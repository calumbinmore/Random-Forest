{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d872f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import random \n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "#from scipy.sparse.linalg import lsqr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  Note   I was having problems with the other virtual environment so i have switched to the porject one instead of test \n",
    "# and sklearn is now working just great."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796941a2",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [ToDO](#ToDO)\n",
    "* [Introduction](#introduction)\n",
    "\n",
    "* [Building](#india)\n",
    "\n",
    "* [Making Predictions](#predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad43f630",
   "metadata": {},
   "source": [
    "## To Do List  <a class='anchor' id='ToDo' ></a>\n",
    "### Updated: 20/09/22\n",
    "\n",
    "* Make a function that takes the test data or real life data and makes predictions by running the data set through each tree I have made and taking an average of the outputted results. \n",
    "\n",
    "* Speed up processes perhaps? By far the slowest one is when I am going through data testing for if splitting it at certain points leads to the greatest drop in variance. maybe there are more efficient ways to do this? Cant think of anything at this moment in time.  \n",
    "\n",
    "* Work on the minimum amount of stuff at the nodes and maximum tree length      Might actually have to learn and do some reading about this. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e772128",
   "metadata": {},
   "source": [
    "## Introduction <a class='anchor' id='introduction'></a>\n",
    "Ok, I am going to try and build a Random Forest Algorithm, which means first I need to figure out how to build a Decision Tree Algorithm before using a range of different Trees with a subset of the data to make the more effective model. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f65634",
   "metadata": {},
   "source": [
    "First up, because I ultimately want to aim for a model which can predict a value of the power usage in the UK which isnt really a categorized value, I think I want to build it so it will have a continuous output. \n",
    "\n",
    "So how does a decision tree work?? We start with, and bear in mind this applies to all types of decision trees, such as classifiers and regression trees,  at the ROOT of the algorithm. Here we have our whole data set, with a Target column, ( the value we want to predict) ie the final price of a house, a list of peoples 100 metre sprint times, the type of fiction which is their favourite. please note that some of these are continuous values while some are obviously categories. We also have in this data a range of different variables which we hope have some relation to the Target data. Relating to the previous examples, we could have the area the house is in, the weights of the sprinters and ages respectively. \n",
    "\n",
    "The data is split by looking at the variable column and posing from it a True/False type of question which splits the data in two. Again lets look at the previous examples. If we were thinking about the house price scenario, this would look like:\n",
    "Is the house in jesmond, True or False, dividing our data into two categories. for the third example, we could split the data into people above or less than 11. \n",
    "\n",
    "which splits we make changes for different types of algorithm and we have a few options but the genera; principle remains the same. We choose the split which leads to the greatest DECREASE in entropy, that is, the one which leads to an increase in homogeneity in the data set on either side of the split. For the favourite book example, I am supposing the target data has a few options, like fantasy, crime fiction, romance and adventure stories. I would imagine that splitting the data based on ages you would get a lot of people below 11 who chose adventure stories and few for the other categories and vice versa for above eleven. This would be a good split to make as one of the groups would be largely made up of one category of target data and the entropy of this group would be low, while there would also be a reduction in entropy for the other group as there is now less data in it and also very few of one type of target data, ie, less of a mixture which is synonymous with entropy. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e1b8e5",
   "metadata": {},
   "source": [
    "## How to split the data?\n",
    "\n",
    "Ok this is a tricky question. There are two problems I think will be tricky to get around and both relate to using continuous data. \n",
    "\n",
    "Having continuous variables means that its harder to pose that yes or no question at each node. For categorical variables, we just say it is or it isnt. for example, the question could be the person is a male or the person isnt male, or they live in Byker or they live elsewhere. For continuous data we need to choose a point and then say ok the variable is more or less than this point. When we are initially feeling about and trying to find where to split the data, we need to try out different points in the data and try an entropy change calculation at each one. The simplest way to do this is to divide the data into say, 10 evenly spaced points from the minimum value to the maximum. At each one do a higher or lower and calculate the entropy change for each one. In reality it will probably be more beneficial to concentrate the points around the average of the variable, presuming it will follow a normal distribution but that makes things harder. \n",
    "\n",
    "The second and more complicated issue is how we split continuous target data. The way I see it we have three options:\n",
    "* Higher or lower than the average (mean or median) of the target data. This doesnt make sense actually haha. \n",
    "* Split the data into sub groups, i dont know how many. For example in house prices we could split up the prices between the minimum and maximum prices into ten equally spaced categories. This would work like: min price= £40,000, max = £540,000 difference=500,000 , categories = £40,000-£90,000, £90,000-£140,00, ......£490,000-£540,000. \n",
    "* Split the data into a higher than or lower than point. Frankly I think it has to be the one above because at the end of the day we want to end up a point where we have a group of data at each leaf node with a certain percentage of them in a certain price range. Nontheless I think there is a place for this method particularly early on in the process, if there is a split that clearly splits the target data between low and high values then that is surely useful.\n",
    "\n",
    "I have watched a video about regression trees and I think the THIRD answer is actually the correct one. Just because we only use higher and lower splits at the decision nodes does not mean that we cannot group the data at the leaf nodes. For example if we split the data at the first decision node into weights =< 85 KG and weights > 85Kg and look at the weights > 85Kg branch, if the next split was between  weights =< 90Kg and weights > 90 Kg then the leaf node on one side would have 85Kg < values =<90Kg . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df4284",
   "metadata": {},
   "source": [
    "Questions: <a class='anchor' id='questions' ></a>\n",
    "* How can a decision tree model on its own be a regression model where it just shuffles data down branches to their end nodes??\n",
    "* How do we group data for continous target data sets?\n",
    "* How to make a decision tree? \n",
    "\n",
    "\n",
    "Answers: \n",
    "A way of grouping data suggested for continous target data is to calculate the variance of th child branches. In an extreme example, if you split the data in such a way that all the values in each sector were identical, then the variance would be 0 and this would be a good split. Calculating $\\sum_{i,j}(x_{i,j}-<x_j>)^2$ and finding the split which gives the minimum variance is a first good method. Maybe this is the way it has to be when delaing with a continuous target data set!! I think the Shannons entropy calculations I was previously thinking about only work for grouped data. \n",
    "### Yes! I have just seen something that says:\n",
    "Node Splitting can be split into two categories with different things in them. \n",
    "\n",
    "#### Categorical Target Variable: <a class='anchor' id='categorical' ></a>\n",
    "\n",
    "* Gini Impurity\n",
    "* Information Gain\n",
    "* Chi-Square\n",
    "\n",
    "#### Continuous Target Variable\n",
    "* Reduction in Variance\n",
    "\n",
    "As I am dealing with a Continuous Problem, it looks like the reduction in variance solution is the way forwards!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811c86a",
   "metadata": {},
   "source": [
    "## Building Our Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32be92",
   "metadata": {},
   "source": [
    "### How to handle data <a class='anchor' id='data'></a>\n",
    "\n",
    "I want to think about how I manage the different types of data that are in the columns. \n",
    "\n",
    "There are a two main types to consider, numerical data and data in text. \n",
    "\n",
    "The second seems like I have to use a one hot encoder, which brings issues in how many unique values we have but should be straightforward. I will try and build a one-hot encoder and compare this to how an actual one-hot encoder works, trying to get the same results. \n",
    "\n",
    "For numerical data I think I can split this into two main categories. Data that is 'continuous', I am not sure if that is the correct word for what i am talking about here because a set of integers is not continuous but what I am referring to is a set which is large and has many unique values, such as the confirmed column in the below table. \n",
    "\n",
    "Additionally we have numerical columns that have only a few unique values. For example if we were looking at the house prices examples, I think something like the number of of bathrooms would probably lie in this. Most houses would only have 1-3 bathrooms and much more than this would be unusual. My question is this: Would it be better to treat columns like this in the same way as continuous data, where i split the data at nodes based on higher and lower calculations, or is it better to one-hot encode data? \n",
    "\n",
    "#### Target Data\n",
    "This is possibly more relevant to target data. For the project I am doing we are working with power output, a continuous column evidently. We could have numerical data that I think would be better treated as a grouping, I mean maybe we need to round number up to integers for stuff like how many people are dying but I am talking about things where there is a small number of unqiue values, for example, how many children a couple have together. I guess this links into what mechanism we use at each decision nodes.\n",
    "\n",
    "For datasets where we have a limited amount of categories and possible values in the target we need to use one of the three methods shown above in [categorical](#categorical). This is actually a simple part of the process. If there are many unique categories then we will use the minimised variance method, whereas if not we will use one of the three methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee29668",
   "metadata": {},
   "source": [
    "## Variance \n",
    "It is actually very straight forwards to calculate the variance of a data series, simply by using $\\color{blue}{df.var()}$, or for specific columns, $\\color{blue}{df['column\\_name'].var()}$ I wanted to type it out because then I could really see what exactly was going on in the calculation. Notice that there is that weird N-1 term in the last line before i return the function and indeed I need to watch out for that in cases of N=1 in the previous loop. This is simply a feature of the variance and it seems like there is not a particularly straightforwards explanation of it. \n",
    "\n",
    "A further note would be that the variance can be described as the squared distance from the mean of the data for each data point that is **averaged across the data points**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98afbf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(data, target):\n",
    "    mean=data[target].sum()/len(data[target])\n",
    "    xs=sum([x*x for x in data[target]])\n",
    "    if len(data[target])==1:\n",
    "        var=(xs-mean**2*len(data[target]))\n",
    "    else:\n",
    "        var=(xs-mean**2*len(data[target]))/(len(data[target])-1)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502c862",
   "metadata": {},
   "source": [
    "## One Hot Encoding \n",
    "My understanding of One-Hot Encoding as remembered from when i looked at it now a long time begins with a column of categorical data. This naturally would break a normal random forest algorithm as they are not built to deal with non-numerical data. The solution is to create a new column for each unique categorical value, containing booleans as either 0 or 1 corresponding to if that particular row of data matches the category. For example, a column of car colours has four options, blue, red, green and silver. This column is replaced by four columns. For data rows where the car is red, the red column has a data value of 1, while the other four have 0. \n",
    "\n",
    "The great thing about this is that it will now work with the normal method of splitting that data. As we are working with boolean values, there is only one way of splitting the data! So once weve split everything up it should be quick!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7760794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHot(df, col):\n",
    "    new=df[col].unique()\n",
    "    if df[col].dtypes=='object':\n",
    "        for i in new:\n",
    "            df[i]=np.zeros(len(df[col])).astype(int)\n",
    "            df[i][df[col]==i]=1\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    return df     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e247c",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4155e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(data, target, min_data, max_branches):\n",
    "    n=0\n",
    "    leaf=[]\n",
    "    v, col, sp, s1, s2=split_new(data, target, min_data)\n",
    "    f=[[col, sp]]\n",
    "    d =  [[[0], s1], [[1], s2]]\n",
    "    while n < max_branches:\n",
    "        n += 1\n",
    "        new=[]\n",
    "        print('the size of d is {}'.format(len(d)))\n",
    "        for i in d:\n",
    "            try:\n",
    "                v, col, sp, s1, s2=split_new(i[1], target, min_data)\n",
    "            except ValueError:\n",
    "                leaf.append(i)\n",
    "            t=i[0].copy()\n",
    "            p=i[0].copy()\n",
    "            leaf.append(i)\n",
    "        else:\n",
    "            t.append(0)\n",
    "            p.append(1)\n",
    "            new.append([t, s1])\n",
    "            new.append([p, s2])\n",
    "            f.append([col, sp, i[0]])\n",
    "        d=new\n",
    "    d.extend(leaf)\n",
    "    return d, f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b57a104",
   "metadata": {},
   "source": [
    "I have got the decision tree to work on a limited subset of the trial data. In this limited case it splits the data into 8 different sets, which is what we want. ALso it records the splitting at each node using a kind of binary to show the node location. This is combined with the split dependent variable and the value it is split at. The problem I am having seems to be at some Nodes there are no ways to split the data that will result in a reduced variance so none are made   I think this is the thing which is messing things up but i Cant be sure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59550a0b",
   "metadata": {},
   "source": [
    "# Second Splitting Algorithm\n",
    "\n",
    "This Algorithm was built because the first one was not working. It would be unable to finsd a suitable plit in a dataset that seemed well suited to reduced variance splitting. I found the solution onnline after being confused for longer than i should have been. The problem i had was thus:\n",
    "* Variance calculations give the average $<x-x_{mean}>^2$, that is, there is an N-1 divisor. \n",
    "* I was doing the calculation to minimise $Var_{new_1}+Var_{new_2}$, specifically in relation to $Var_{original}$. \n",
    "* Really we want to see the reduction in variance per datapoint. When adding two average variances we are not taking this into account. \n",
    "* need to introduce a weighting to the variances. This is easily calculated as $N_{subset}$ the(the subset we were calculating the variance for) divided by $N_{total}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9955eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_new(dataframe, target, min_leaf):\n",
    "    n=dataframe[target].unique().sum()\n",
    "    variables=dataframe.drop(target, axis=1, inplace=False) #this drops the target column from the data for the next line\n",
    "    var=[variance(dataframe, target), 0,0,0, 0] # making an array to contain information about how the split is made\n",
    "    for col in variables.columns:\n",
    "        if dataframe[col].dtypes=='int64' or 'float64':\n",
    "            c=dataframe.sort_values(col) #This sorts each of the variable columns \n",
    "            u=c[col].unique()            \n",
    "            for i in range(0, len(u)-1): #np.linspace(0, len(u)-1):\n",
    "                split=(u[i]+u[i+1])/2\n",
    "                l=len(dataframe)\n",
    "                s1=pd.DataFrame(dataframe[dataframe[col]<split])\n",
    "                s2=pd.DataFrame(dataframe[dataframe[col]>split])    \n",
    "                v=variance(s1, target)*len(s1)/l+variance(s2, target)*len(s2)/l # This is where I introduced a weighting, outlined above\n",
    "                if v<var[0] and len(s1)>min_leaf and len(s2)>min_leaf:\n",
    "                    var=[v, col, split, s1, s2]\n",
    "    if var[1]==0:\n",
    "        var='leaf'\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c95b83",
   "metadata": {},
   "source": [
    "# Plotting Code\n",
    "It seems it will be helpful to be able to see how the data has been split, depending on a variable and with the option of plotting all splits together or sharing an axis but with different plots, to allow for comparison. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a40ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, variable, target):\n",
    "    graph=input('select whether you want singular or multiple')\n",
    "    groups=len(data)\n",
    "    if graph=='singular':\n",
    "        fig, ax =plt.subplots(figsize=(15,15))\n",
    "        for i in range(groups-1):\n",
    "            ax.scatter(data[i][1][variable],data[i][1][target])\n",
    "    elif graph == 'multiple':\n",
    "        fig, axs =plt.subplots(groups, figsize=(10,5*groups), sharex=True)\n",
    "        axs[0].scatter(data[0][1][variable], data[0][1][target])\n",
    "        for i in range(1, groups-1):\n",
    "            axs[i].scatter(data[i][1][variable], data[i][1][target])\n",
    "    else:\n",
    "        print('you need to choose between multiple and singular')\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d92986",
   "metadata": {},
   "source": [
    "# House price Data\n",
    "How prices in India, with straighforwards variable columns. \n",
    "\n",
    "\n",
    "On Kaggle this is saved as:\n",
    "**House Rent Prediction Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7e3e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4746\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "house=pd.read_csv('data\\House_Rent_Dataset.csv')\n",
    "house.drop([\"Posted On\", 'Area Locality'], axis=1, inplace=True ) #With the one-hot encoding i am doing this makes the dataframes too long\n",
    "for i in house.columns:\n",
    "    house=OneHot(house, i)\n",
    "print(len(house))\n",
    "train_house=house.head(4000)\n",
    "test_house=house.tail(746)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee46c9b",
   "metadata": {},
   "source": [
    "# Decision tree 2\n",
    "This is a modified one which will look more towards the second part, classifying new data. \n",
    "\n",
    "The difference is now I dont just care about getting data split and leaf nodes with the variance minimised but also I am keeping track of the splitting that occurs at each node. There are three different bits of information that I need to keep track of:\n",
    "* Which variable is the data being split on\n",
    "* At what point in the data it is split\n",
    "* for which part of the tree and therefore subset of data is the split for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2382127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_2(data, target, min_data, max_branches):\n",
    "    n=0\n",
    "    leaf=[]\n",
    "    v, col, sp, s1, s2=split_new(data, target, min_data)\n",
    "    f=[[col, sp, 0]]\n",
    "    d =  [[[0], s1], [[1], s2]]\n",
    "    while n < max_branches:\n",
    "        n += 1\n",
    "        new=[]\n",
    "        print('the size of d is {}'.format(len(d)))\n",
    "        for i in d:\n",
    "            #print('checking whats up')\n",
    "            try:\n",
    "                v, col, sp, s1, s2=split_new(i[1], target, min_data)\n",
    "                t=i[0].copy()\n",
    "                p=i[0].copy()\n",
    "                if col == 0: #The idea of this is that, from the new_split function, if the data cannot be split anymore, the col column will be empty so we know to add this to the list\n",
    "                    leaf.append(i)\n",
    "                    f.append([0, 0, i[0], i[1][target].mean()])\n",
    "                else:#elif len(i[1])>min_data:\n",
    "                    t.append(0)\n",
    "                    p.append(1)\n",
    "                    new.append([t, s1])\n",
    "                    new.append([p, s2])\n",
    "                    f.append([col, sp, i[0]])\n",
    "            except ValueError: #This was brought in to sort a weird error where the algortithm was only finding 4 values from the list when there was five\n",
    "                leaf.append(i)\n",
    "                f.append([0, 0, i[0], i[1][target].mean()])\n",
    "        d=new\n",
    "    for j in d:\n",
    "        f.append([0, 0, j[0], j[1][target].mean()])\n",
    "    d.extend(leaf)\n",
    "    return d, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fcc7e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 8\n",
      "the size of d is 14\n",
      "[['Bathroom', 3.5, 0], ['Contact Owner', 0.5, [0]], ['Mumbai', 0.5, [1]], ['Bathroom', 2.5, [0, 0]], ['Size', 1424.5, [0, 1]], ['Size', 2771.0, [1, 0]], ['Size', 2940.0, [1, 1]], ['Mumbai', 0.5, [0, 0, 0]], ['Size', 2465.0, [0, 0, 1]], ['Mumbai', 0.5, [0, 1, 0]], ['Bathroom', 2.5, [0, 1, 1]], ['Unfurnished', 0.5, [1, 0, 0]], ['Size', 3175.0, [1, 0, 1]], ['Size', 1777.5, [1, 1, 0]], [0, 0, [1, 1, 1], 598461.5384615385], ['Size', 1262.0, [0, 0, 0, 0]], ['Size', 833.5, [0, 0, 0, 1]], ['Mumbai', 0.5, [0, 0, 1, 0]], ['Size', 2840.0, [0, 0, 1, 1]], ['Bathroom', 1.5, [0, 1, 0, 0]], ['Size', 707.0, [0, 1, 0, 1]], ['BHK', 2.5, [0, 1, 1, 0]], ['Delhi', 0.5, [0, 1, 1, 1]], ['Size', 2158.5, [1, 0, 0, 0]], [0, 0, [1, 0, 0, 1], 124818.18181818182], [0, 0, [1, 0, 1, 0], 136500.0], [0, 0, [1, 0, 1, 1], 191296.2962962963], ['Size', 1327.5, [1, 1, 0, 0]], ['Size', 2145.0, [1, 1, 0, 1]], [0, 0, [0, 0, 0, 0, 0], 17372.78947368421], [0, 0, [0, 0, 0, 0, 1], 42000.0], [0, 0, [0, 0, 0, 1, 0], 43640.25432098765], [0, 0, [0, 0, 0, 1, 1], 93804.75], [0, 0, [0, 0, 1, 0, 0], 50630.758241758245], [0, 0, [0, 0, 1, 0, 1], 114884.16949152542], [0, 0, [0, 0, 1, 1, 0], 406500.0], [0, 0, [0, 0, 1, 1, 1], 102909.09090909091], [0, 0, [0, 1, 0, 0, 0], 9127.187308085977], [0, 0, [0, 1, 0, 0, 1], 16445.149787234044], [0, 0, [0, 1, 0, 1, 0], 24710.493055555555], [0, 0, [0, 1, 0, 1, 1], 49035.71428571428], [0, 0, [0, 1, 1, 0, 0], 18028.03125], [0, 0, [0, 1, 1, 0, 1], 26970.744680851065], [0, 0, [0, 1, 1, 1, 0], 35474.58252427184], [0, 0, [0, 1, 1, 1, 1], 69928.57142857143], [0, 0, [1, 0, 0, 0, 0], 37941.17647058824], [0, 0, [1, 0, 0, 0, 1], 98705.88235294117], [0, 0, [1, 1, 0, 0, 0], 95384.61538461539], [0, 0, [1, 1, 0, 0, 1], 176500.0], [0, 0, [1, 1, 0, 1, 0], 268076.92307692306], [0, 0, [1, 1, 0, 1, 1], 327727.2727272727]]\n"
     ]
    }
   ],
   "source": [
    "M, E=decision_tree_2(train_house, 'Rent', 10, 4)# Changed to 2 branches to compare to my decision tree model\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b674279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select whether you want singular or multiplesingular\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(M, 'Size', 'Rent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02915af",
   "metadata": {},
   "source": [
    "# 12/09/2022  Decision treeing data\n",
    "\n",
    "I am now at a stage where I have my decision tree and i need to start passing data rows down the branches to the leaf nodes. Currently the 'tree' is in the form of a list of sublists, each containing infomation about a node position and the splitting value. I think the best way to do it, while time expensive ,is to search through this jumble, finding the appropriate node at each layer. Thinking about it, It would be far easier if the tree was somehow reorgansied in a way similar to how it is visualised. It is easiest to sort the tree before putting data into it, rather than having to search through each node every time. that way when we know how the data is in respect to each node we know where to send it next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b597323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plant(leaves):\n",
    "    E=leaves\n",
    "    max=len(E[-1][2])\n",
    "    branch=[]\n",
    "    for i in range(0, max+1):\n",
    "        y=np.zeros(2**i).tolist()\n",
    "        for j in E[1:]:\n",
    "            if len(j[2])==i:\n",
    "                n=0           \n",
    "                for k in range(len(j[2])):\n",
    "                    if j[2][k]==1:\n",
    "                        n+=2**(len(j[2])-k-1)\n",
    "                y[n]=j \n",
    "        branch.append(y)\n",
    "    branch[0][0]=E[0]\n",
    "    return branch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85b8cd",
   "metadata": {},
   "source": [
    "Happily, it seems that the above code does work and it formats the information given by the training data into something resembling a tree, which hopefully we can use to make decisions. \n",
    "\n",
    "I have done this by means of a list with sublists inside which represent each layer of nodes down the tree. Wherever we reach a leaf before the end of the tree the spaces below which would represent further node are instead merely 0s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44bc16f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bathroom', 3.5, 0]\n",
      "[[['Bathroom', 3.5, 0]], [['Contact Owner', 0.5, [0]], ['Mumbai', 0.5, [1]]], [['Bathroom', 2.5, [0, 0]], ['Size', 1424.5, [0, 1]], ['Size', 2771.0, [1, 0]], ['Size', 2940.0, [1, 1]]], [['Mumbai', 0.5, [0, 0, 0]], ['Size', 2465.0, [0, 0, 1]], ['Mumbai', 0.5, [0, 1, 0]], ['Bathroom', 2.5, [0, 1, 1]], ['Unfurnished', 0.5, [1, 0, 0]], ['Size', 3175.0, [1, 0, 1]], ['Size', 1777.5, [1, 1, 0]], [0, 0, [1, 1, 1], 598461.5384615385]], [['Size', 1262.0, [0, 0, 0, 0]], ['Size', 833.5, [0, 0, 0, 1]], ['Mumbai', 0.5, [0, 0, 1, 0]], ['Size', 2840.0, [0, 0, 1, 1]], ['Bathroom', 1.5, [0, 1, 0, 0]], ['Size', 707.0, [0, 1, 0, 1]], ['BHK', 2.5, [0, 1, 1, 0]], ['Delhi', 0.5, [0, 1, 1, 1]], ['Size', 2158.5, [1, 0, 0, 0]], [0, 0, [1, 0, 0, 1], 124818.18181818182], [0, 0, [1, 0, 1, 0], 136500.0], [0, 0, [1, 0, 1, 1], 191296.2962962963], ['Size', 1327.5, [1, 1, 0, 0]], ['Size', 2145.0, [1, 1, 0, 1]], 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0], 17372.78947368421], [0, 0, [0, 0, 0, 0, 1], 42000.0], [0, 0, [0, 0, 0, 1, 0], 43640.25432098765], [0, 0, [0, 0, 0, 1, 1], 93804.75], [0, 0, [0, 0, 1, 0, 0], 50630.758241758245], [0, 0, [0, 0, 1, 0, 1], 114884.16949152542], [0, 0, [0, 0, 1, 1, 0], 406500.0], [0, 0, [0, 0, 1, 1, 1], 102909.09090909091], [0, 0, [0, 1, 0, 0, 0], 9127.187308085977], [0, 0, [0, 1, 0, 0, 1], 16445.149787234044], [0, 0, [0, 1, 0, 1, 0], 24710.493055555555], [0, 0, [0, 1, 0, 1, 1], 49035.71428571428], [0, 0, [0, 1, 1, 0, 0], 18028.03125], [0, 0, [0, 1, 1, 0, 1], 26970.744680851065], [0, 0, [0, 1, 1, 1, 0], 35474.58252427184], [0, 0, [0, 1, 1, 1, 1], 69928.57142857143], [0, 0, [1, 0, 0, 0, 0], 37941.17647058824], [0, 0, [1, 0, 0, 0, 1], 98705.88235294117], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 0], 95384.61538461539], [0, 0, [1, 1, 0, 0, 1], 176500.0], [0, 0, [1, 1, 0, 1, 0], 268076.92307692306], [0, 0, [1, 1, 0, 1, 1], 327727.2727272727], 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(E[0])\n",
    "#print(branch[2][-1])\n",
    "#print(M[-2][1])\n",
    "#plt.scatter(M[-2][1]['Size'],M[-2][1]['Rent'])\n",
    "print(plant(E))\n",
    "branch=plant(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1449dc",
   "metadata": {},
   "source": [
    "# Making Predictions <a class='anchor' id='predictions' ></a>\n",
    "\n",
    "\n",
    "Now to start feeding data into my model and making predicitons from it. Essentially all I need is the Node tree which I built in the previous section. Data will be fed down this tree with each node outcome directing the data to the next node until it reaches a leaf. At this point the target value given to the data point is the average of all training data target values at that leaf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a2aece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, branch, name):\n",
    "    data=data.reset_index(drop=True)\n",
    "    data[name]=np.zeros(len(data))\n",
    "    for j in range(len(data)):\n",
    "        p=data.loc[j, :]\n",
    "        if p[branch[0][0][0]]<branch[0][0][1]:\n",
    "            sep=[0] \n",
    "        else:\n",
    "            sep=[1]\n",
    "        val='bol'\n",
    "        for i in range(1, len(branch[1:])):\n",
    "            n=0           \n",
    "            for k in range(len(sep)):\n",
    "                if sep[k]==1:\n",
    "                    n+=2**(i-k-1)\n",
    "            if len(branch[i][n])==4:\n",
    "                val=branch[i][n][3]\n",
    "                break ##Added to try and sort out code not working. If this above condition is made we have reached \n",
    "                # the leaf and need to not try and travel further down the tree!\n",
    "            elif p[branch[i][n][0]]<branch[i][n][1]:\n",
    "                sep.append(0)\n",
    "            else:\n",
    "                sep.append(1)\n",
    "        if val=='bol':\n",
    "            n=0           \n",
    "            for k in range(len(sep)):\n",
    "                if sep[k]==1:\n",
    "                    n+=2**(len(sep)-k-1)\n",
    "            val=branch[-1][n][3]\n",
    "        data.at[j, name]=val\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "661e83f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BHK    Rent  Size  Bathroom  Ground out of 2  ...  Family  Contact Owner  \\\n",
      "0      2   18000   242         2                0  ...       0              1   \n",
      "1      2    9500   720         2                0  ...       0              1   \n",
      "2      3   49000  1800         3                0  ...       0              0   \n",
      "3      1    9000   450         1                0  ...       0              1   \n",
      "4      2  130000   130         2                0  ...       0              1   \n",
      "..   ...     ...   ...       ...              ...  ...     ...            ...   \n",
      "741    2   15000  1000         2                0  ...       0              1   \n",
      "742    3   29000  2000         3                0  ...       0              1   \n",
      "743    3   35000  1750         3                0  ...       0              0   \n",
      "744    3   45000  1500         2                0  ...       1              0   \n",
      "745    2   15000  1000         2                0  ...       0              1   \n",
      "\n",
      "     Contact Agent  Contact Builder   predictions  \n",
      "0                0                0  16445.149787  \n",
      "1                0                0  16445.149787  \n",
      "2                1                0  50630.758242  \n",
      "3                0                0   9127.187308  \n",
      "4                0                0  16445.149787  \n",
      "..             ...              ...           ...  \n",
      "741              0                0  16445.149787  \n",
      "742              0                0  35474.582524  \n",
      "743              1                0  50630.758242  \n",
      "744              1                0  42000.000000  \n",
      "745              0                0  16445.149787  \n",
      "\n",
      "[746 rows x 503 columns]\n"
     ]
    }
   ],
   "source": [
    "test_house_2=test_house.copy()\n",
    "test_house_predicts=predict(test_house_2, branch, 'predictions')\n",
    "print(test_house_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "353a5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_house_predicts['predictions'])\n",
    "varr=(test_house_predicts['Rent']-test_house_predicts['predictions'])**2\n",
    "#print(varr)\n",
    "#print(varr.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d008b5",
   "metadata": {},
   "source": [
    "# Moving from Decision Tree to Random Forest\n",
    "Now that I have a working decision tree I have some options for my next step. I could look into how deep I want my trees to go, what I should set the minimum leaf node to be and generally have a look at how to fight overfitting and underfitting. This has never really appealed haha so I am quite keen for the second option which is to look at the **ensemble** version, which is the Random Forest model. \n",
    "\n",
    "There are two ways that we change the data used for each decision tree within the forest. \n",
    "* Select a random subset of the data\n",
    "* Only use some of the feautures (The variable columns) of the data in each decision tree\n",
    "\n",
    "\n",
    "The second I think is really smart as some variable columns will have a strign influence over the target column and so will tend to dominate the decision trees.   Leaving them out seems kind of good. It will let the other variable columns have a turn.\n",
    "I need to know:\n",
    "* How to split the data, what percentage of data do we use in each tree\n",
    "* Which columns to choose from at each node. \n",
    "* Eventually need to find how many trees I need.  \n",
    "\n",
    "\n",
    "**How many trees?** Seen an article which is saying that basically the more trees you include the better your results but then we have the drawbacks of processing time. It seems to the base that around 60 Trees would be great. Have to take into account that my algorithm is a bit slow even for one decision tree!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Some useful definition:\n",
    "* **Features/Predictors:** the 'dependent' variables, the columns in the data which arent target data. \n",
    "* **Column Sampling:** the practice of only using a few cols.\n",
    "* **Maximum Features** This is what sklearn calls the setting where you decide the amount of randomly selected features which can split the data at each node. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95370a0d",
   "metadata": {},
   "source": [
    "### Which data to use for each Tree / Sampling\n",
    "**Bootstrapping** Drawing sub-samples from the main sample and repeating multiple times, each one drawing different random ones from a complete main sample. \n",
    "\n",
    "**Key Point** It seems to be the case that when we bootstrap we select a data point and replace it straight away **So it can be selected more than one time in the sample!** The actual size should match the original sample size. \n",
    "\n",
    "\n",
    "**Bagging**-Bootstrap + Aggregation.  I think this is just doing boostrapping as outlined above and then taking an average of the produced results. \n",
    "\n",
    "Interesting fact about bootstrapping:\n",
    "\n",
    "To begin with we have a data set of size n. The probability of selecting a specific sample is given by $\\frac{1}{n}$. I think it is important to note that in this mathematical explanation, as in the bootstrapping we will do in the random forest, we keep 'fishing' from the original sample, once weve selected a sample from it we can take that sample again, it doesnt change in size or anything like that. \n",
    "Probability of not getting selected:\n",
    "\n",
    "$1-\\frac{1}{n}$\n",
    "\n",
    "If we repeat this n times, which will give us a bootstrapped sample of size n:\n",
    "\n",
    "$(1-\\frac{1}{n})^n$ \n",
    "\n",
    "This is the probability of NOT selecting a given sample. \n",
    "\n",
    "I dont really know how to prove it other than like :\n",
    "\n",
    "$(1+\\frac{x}{n})^n=(1+\\frac{2x}{n}+\\frac{x^2}{n^2})(1+\\frac{x}{n})^{n-2}=(1+\\frac{3x}{n}+\\frac{3x^2}{n^2}+\\frac{x^3}{n^3})(1+\\frac{x}{n})^{n-3}$ \n",
    "\n",
    "Basically this seems to come out as:\n",
    "\n",
    "$(1+\\frac{x}{n})^n=1+x+\\frac{x^2}{n}+\\frac{x^3}{n^2}.....$\n",
    "\n",
    " this is not quite the same thing as \n",
    " \n",
    " $e^x=1+x+\\frac{x^2}{2}+....$\n",
    " so maybe I have gotten confused at some point.\n",
    " \n",
    " Anyhoo, setting $x=-1$ we get $e^{-1}$=0.32 thats the probability of a data point NOT being selected in a bootstrapping of the same size as the original sampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f956ad",
   "metadata": {},
   "source": [
    "## Building a bootstrapper.\n",
    "\n",
    "Now I need to get my bootstrapped data. I need to use replacement when I do this. This is simply for training a model so dont need to worry about things too much. \n",
    "\n",
    "\n",
    "This is to get bootstrapped data for which to train different decision trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e41600e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(train):\n",
    "    boot=train.copy()\n",
    "    n=len(boot)\n",
    "    vals=np.random.randint(n, size=n)\n",
    "    b=pd.DataFrame()\n",
    "    for i in vals:\n",
    "        b=pd.concat([b,boot.loc[i,:]], axis=1)\n",
    "    b=b.T#.reset_index(drop=True)   ## Note sure if I need to reset the index for the algorithm to work or not.\n",
    "    return b\n",
    "b=bootstrap(train_house.head(100))\n",
    "#print(train_house.head(100))\n",
    "#print(len(pd.unique(b.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05436eb",
   "metadata": {},
   "source": [
    "## Column Sampling\n",
    "\n",
    "### Which predictors used at each node??\n",
    "\n",
    "* For each tree you set a certain number of categories available at each node, say a random 10 percent of the total. At the next nodes in the tree you change which predictors are available to split the data. **Columns are not randomly selected at tree level but change at different nodes in the tree!**\n",
    "* The amount of predictors available at each node has been recommended as $\\sqrt{M}$, where M is the total amount of predictors, while I have also seen it recommended to use $\\frac{M}{3}$ for regression models which is what I am using. \n",
    "\n",
    "In regards to how many of the predictors we should randomly choose from at each node, I think the idea is to try and get less prominent nodes involved. Even though we are randomly sampling the train data for each different tree, we expect that there will be some predictors which will lead to a good decrease in variance and will be favoured. Somehow it seems it will improve the model to allow other factors which offer good and useful splitting in the data, just less good. It kind of makes sense that it still looks for good splitting but it just means that other variables and their influence come to the fore. Thinking about it, it makes sense and seems like a good idea. $\\frac{M}{3}$ sounds good.\n",
    "\n",
    "**Note:** Something I need to think about is how we deal with the categorical variables which I treated with the oneHotEncodign method. This kind of messes things up when we dont use all of the predictors because there are as many columns as there are different variables in the categorical column. \n",
    "\n",
    "I will start with the decision tree maker that I previously made and I just need to make some small changes in it. I think actually I need to make the changes to the split code that is used within this as this is the code which is used to decide how the split is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "316497da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_trees(data, target, min_data, max_branches, max_features):\n",
    "    print('I hope youve inputted the max_features option as a decimal percentage')\n",
    "    #max_features=input('please input a decimal to get a percentage of the total columns')\n",
    "    #max_features=float(max_features)\n",
    "    n=0\n",
    "    leaf=[]\n",
    "    v, col, sp, s1, s2=split_rf(data, target, min_data, max_features)\n",
    "    f=[[col, sp, 0]]\n",
    "    d =  [[[0], s1], [[1], s2]]\n",
    "    while n < max_branches:\n",
    "        n += 1\n",
    "        new=[]\n",
    "        print('the size of d is {}'.format(len(d)))\n",
    "        for i in d:\n",
    "            #print('checking whats up')\n",
    "            try:\n",
    "                v, col, sp, s1, s2=split_rf(i[1], target, min_data, max_features)\n",
    "                t=i[0].copy()\n",
    "                p=i[0].copy()\n",
    "                if col == 0: #The idea of this is that, from the new_split function, if the data cannot be split anymore, the col column will be empty so we know to add this to the list\n",
    "                    leaf.append(i)\n",
    "                    f.append([0, 0, i[0], i[1][target].mean()])\n",
    "                else:#elif len(i[1])>min_data:\n",
    "                    t.append(0)\n",
    "                    p.append(1)\n",
    "                    new.append([t, s1])\n",
    "                    new.append([p, s2])\n",
    "                    f.append([col, sp, i[0]])\n",
    "            except ValueError: #This was brought in to sort a weird error where the algortithm was only finding 4 values from the list when there was five\n",
    "                leaf.append(i)\n",
    "                f.append([0, 0, i[0], i[1][target].mean()])\n",
    "        d=new\n",
    "    for j in d:\n",
    "        f.append([0, 0, j[0], j[1][target].mean()])\n",
    "    d.extend(leaf)\n",
    "    return d, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9095d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rf(dataframe, target, min_leaf, max_features):\n",
    "    n=dataframe[target].unique().sum()\n",
    "    variables=dataframe.drop(target, axis=1, inplace=False) #this drops the target column from the data for the next line\n",
    "    n_cols=round(len(variables.columns)*max_features) #The number of random columns we will look at\n",
    "    options=variables.columns.tolist() #A list of all column names in the data set\n",
    "    select=random.sample(range(len(variables.columns)), n_cols) # how to randomly sel\n",
    "    colls=[]\n",
    "    for i in select:\n",
    "        colls.append(options[i])\n",
    "    #print('ncols={}'.format(n_cols))\n",
    "    #print('options={}'.format(options))\n",
    "    #print('select={}'.format(select))\n",
    "    #print('the possible cols are{}'.format(colls))\n",
    "    var=[variance(dataframe, target), 0,0,0, 0] # making an array to contain information about how the split is made\n",
    "    for col in colls:\n",
    "        if dataframe[col].dtypes=='int64' or 'float64':\n",
    "            c=dataframe.sort_values(col) #This sorts each of the variable columns \n",
    "            u=c[col].unique()            \n",
    "            for i in range(0, len(u)-1): #np.linspace(0, len(u)-1):\n",
    "                split=(u[i]+u[i+1])/2\n",
    "                l=len(dataframe)\n",
    "                s1=pd.DataFrame(dataframe[dataframe[col]<split])\n",
    "                s2=pd.DataFrame(dataframe[dataframe[col]>split])    \n",
    "                v=variance(s1, target)*len(s1)/l+variance(s2, target)*len(s2)/l # This is where I introduced a weighting, outlined above\n",
    "                if v<var[0] and len(s1)>min_leaf and len(s2)>min_leaf:\n",
    "                    var=[v, col, split, s1, s2]\n",
    "    if var[1]==0:\n",
    "        var='leaf'\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2240b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BHK</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Size</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Ground out of 2</th>\n",
       "      <th>...</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>Family</th>\n",
       "      <th>Contact Owner</th>\n",
       "      <th>Contact Agent</th>\n",
       "      <th>Contact Builder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>1100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20000</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7500</td>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BHK   Rent  Size  Bathroom  Ground out of 2  ...  Bachelors  Family  \\\n",
       "0    2  10000  1100         2                1  ...          0       0   \n",
       "1    2  20000   800         1                0  ...          0       0   \n",
       "2    2  17000  1000         1                0  ...          0       0   \n",
       "3    2  10000   800         1                0  ...          0       0   \n",
       "4    2   7500   850         1                0  ...          1       0   \n",
       "\n",
       "   Contact Owner  Contact Agent  Contact Builder  \n",
       "0              1              0                0  \n",
       "1              1              0                0  \n",
       "2              1              0                0  \n",
       "3              1              0                0  \n",
       "4              1              0                0  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accc2c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n"
     ]
    }
   ],
   "source": [
    "data, splits=rf_trees(train_house, 'Rent', 10, 2, 0.33)\n",
    "#print(E)\n",
    "#print(splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e0591",
   "metadata": {},
   "source": [
    "As predicted, the OneHotEncoding is throwing up some problems!! There are simply too many columns, particularly looking at theone which says what kind of apartment it is!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80461f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4746\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "house=pd.read_csv('data\\House_Rent_Dataset.csv')\n",
    "house.drop([\"Posted On\", 'Area Locality', 'Floor'], axis=1, inplace=True ) #With the one-hot encoding i am doing this makes the dataframes too long\n",
    "for i in house.columns:\n",
    "    house=OneHot(house, i)\n",
    "print(len(house))\n",
    "train=house.head(4000)\n",
    "test=house.tail(746)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb40c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, splits=rf_trees(train, 'Rent', 10, 4, 0.33)\n",
    "#print(E)\n",
    "#print(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627e11e",
   "metadata": {},
   "source": [
    "## Combining into a forest\n",
    "We are now at the point where we need to combine the previous two features, Bootstrapping and column sampling to start training multiple trees. The output of this section will hopefully be a list of trees in their list form I built previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f2cf6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(training_data, target, min_data, max_branches, max_features, n_trees):\n",
    "    trees=[]\n",
    "    for i in range(n_trees):\n",
    "        data=bootstrap(training_data)\n",
    "        #print(data)\n",
    "        leaves, splits=rf_trees(data, target, min_data, max_branches, max_features)\n",
    "        #print(splits)\n",
    "        branch=plant(splits)\n",
    "        print(branch)\n",
    "        trees.append(branch)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dacb21",
   "metadata": {},
   "source": [
    "### General Notes\n",
    "I have done a test run of my random forest algorithm and it seems to work! It is slow though so Maybe I will look at means of speediing things up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a218ab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 6\n",
      "the size of d is 12\n",
      "the size of d is 18\n",
      "[[['Bathroom', 3.5, 0]], [['Bathroom', 2.5, [0]], ['Mumbai', 0.5, [1]]], [['Bathroom', 1.5, [0, 0]], ['Contact Agent', 0.5, [0, 1]], ['Bangalore', 0.5, [1, 0]], [0, 0, [1, 1], 251709.67741935485]], [['Kolkata', 0.5, [0, 0, 0]], ['Chennai', 0.5, [0, 0, 1]], ['Unfurnished', 0.5, [0, 1, 0]], ['Family', 0.5, [0, 1, 1]], ['Bachelors/Family', 0.5, [1, 0, 0]], ['Size', 3000.0, [1, 0, 1]], 0.0, 0.0], [['Contact Owner', 0.5, [0, 0, 0, 0]], ['Size', 690.0, [0, 0, 0, 1]], ['Bangalore', 0.5, [0, 0, 1, 0]], ['Bachelors', 0.5, [0, 0, 1, 1]], ['Delhi', 0.5, [0, 1, 0, 0]], ['Size', 1550.0, [0, 1, 0, 1]], ['Size', 2465.0, [0, 1, 1, 0]], ['Carpet Area', 0.5, [0, 1, 1, 1]], [0, 0, [1, 0, 0, 0], 102440.0], ['Delhi', 0.5, [1, 0, 0, 1]], [0, 0, [1, 0, 1, 0], 95250.0], [0, 0, [1, 0, 1, 1], 177090.9090909091], 0.0, 0.0, 0.0, 0.0], [['Mumbai', 0.5, [0, 0, 0, 0, 0]], ['Furnished', 0.5, [0, 0, 0, 0, 1]], ['Size', 515.0, [0, 0, 0, 1, 0]], ['Furnished', 0.5, [0, 0, 0, 1, 1]], ['Contact Owner', 0.5, [0, 0, 1, 0, 0]], ['Size', 1225.0, [0, 0, 1, 0, 1]], ['Contact Agent', 0.5, [0, 0, 1, 1, 0]], ['Semi-Furnished', 0.5, [0, 0, 1, 1, 1]], ['Size', 1419.0, [0, 1, 0, 0, 0]], [0, 0, [0, 1, 0, 0, 1], 57800.0], [0, 0, [0, 1, 0, 1, 0], 19777.777777777777], [0, 0, [0, 1, 0, 1, 1], 31000.0], ['Delhi', 0.5, [0, 1, 1, 0, 0]], [0, 0, [0, 1, 1, 0, 1], 555000.0], [0, 0, [0, 1, 1, 1, 0], 39909.09090909091], [0, 0, [0, 1, 1, 1, 1], 82782.98113207547], 0.0, 0.0, [0, 0, [1, 0, 0, 1, 0], 105318.18181818182], ['Size', 2650.0, [1, 0, 0, 1, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 14285.067164179105], [0, 0, [0, 0, 0, 0, 0, 1], 37329.78723404255], [0, 0, [0, 0, 0, 0, 1, 0], 10469.471488178026], [0, 0, [0, 0, 0, 0, 1, 1], 16686.04651162791], [0, 0, [0, 0, 0, 1, 0, 0], 5707.194244604317], [0, 0, [0, 0, 0, 1, 0, 1], 7701.666666666667], [0, 0, [0, 0, 0, 1, 1, 0], 10448.574074074075], [0, 0, [0, 0, 0, 1, 1, 1], 13250.0], [0, 0, [0, 0, 1, 0, 0, 0], 50097.10810810811], [0, 0, [0, 0, 1, 0, 0, 1], 21726.170833333334], [0, 0, [0, 0, 1, 0, 1, 0], 16669.843949044585], [0, 0, [0, 0, 1, 0, 1, 1], 28753.846153846152], [0, 0, [0, 0, 1, 1, 0, 0], 14870.262755102041], [0, 0, [0, 0, 1, 1, 0, 1], 25257.085714285713], [0, 0, [0, 0, 1, 1, 1, 0], 50802.32558139535], [0, 0, [0, 0, 1, 1, 1, 1], 19593.75], [0, 0, [0, 1, 0, 0, 0, 0], 24209.677419354837], [0, 0, [0, 1, 0, 0, 0, 1], 34312.87234042553], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [0, 1, 1, 0, 0, 0], 90191.94642857143], [0, 0, [0, 1, 1, 0, 0, 1], 50816.666666666664], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 0, 0, 1, 1, 0], 73181.81818181818], [0, 0, [1, 0, 0, 1, 1, 1], 203090.9090909091], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 8\n",
      "the size of d is 14\n",
      "the size of d is 18\n",
      "[[['Bathroom', 3.5, 0]], [['Carpet Area', 0.5, [0]], ['Mumbai', 0.5, [1]]], [['Bathroom', 2.5, [0, 0]], ['Bathroom', 2.5, [0, 1]], ['Size', 2771.0, [1, 0]], ['Size', 2900.0, [1, 1]]], [['Bathroom', 1.5, [0, 0, 0]], ['Size', 1975.0, [0, 0, 1]], ['Bathroom', 1.5, [0, 1, 0]], ['Chennai', 0.5, [0, 1, 1]], ['Size', 2158.5, [1, 0, 0]], ['Semi-Furnished', 0.5, [1, 0, 1]], ['Family', 0.5, [1, 1, 0]], [0, 0, [1, 1, 1], 606842.1052631579]], [['Size', 572.5, [0, 0, 0, 0]], ['Size', 1877.5, [0, 0, 0, 1]], ['Contact Owner', 0.5, [0, 0, 1, 0]], [0, 0, [0, 0, 1, 1], 77970.58823529411], ['Contact Agent', 0.5, [0, 1, 0, 0]], ['Mumbai', 0.5, [0, 1, 0, 1]], ['Delhi', 0.5, [0, 1, 1, 0]], ['Contact Agent', 0.5, [0, 1, 1, 1]], ['Semi-Furnished', 0.5, [1, 0, 0, 0]], [0, 0, [1, 0, 0, 1], 88551.72413793103], [0, 0, [1, 0, 1, 0], 145333.33333333334], [0, 0, [1, 0, 1, 1], 191000.0], ['BHK', 3.5, [1, 1, 0, 0]], [0, 0, [1, 1, 0, 1], 246250.0], 0.0, 0.0], [['Bangalore', 0.5, [0, 0, 0, 0, 0]], ['Mumbai', 0.5, [0, 0, 0, 0, 1]], ['Contact Agent', 0.5, [0, 0, 0, 1, 0]], [0, 0, [0, 0, 0, 1, 1], 56071.42857142857], ['Bangalore', 0.5, [0, 0, 1, 0, 0]], ['Delhi', 0.5, [0, 0, 1, 0, 1]], 0.0, 0.0, ['Size', 753.0, [0, 1, 0, 0, 0]], ['Bangalore', 0.5, [0, 1, 0, 0, 1]], ['Size', 1263.0, [0, 1, 0, 1, 0]], ['Unfurnished', 0.5, [0, 1, 0, 1, 1]], ['Contact Agent', 0.5, [0, 1, 1, 0, 0]], ['Size', 1275.0, [0, 1, 1, 0, 1]], [0, 0, [0, 1, 1, 1, 0], 21383.333333333332], ['Bachelors/Family', 0.5, [0, 1, 1, 1, 1]], [0, 0, [1, 0, 0, 0, 0], 73333.33333333333], [0, 0, [1, 0, 0, 0, 1], 32100.0], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 0], 142628.57142857142], ['Bathroom', 4.5, [1, 1, 0, 0, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 9523.289156626506], [0, 0, [0, 0, 0, 0, 0, 1], 8045.121951219512], [0, 0, [0, 0, 0, 0, 1, 0], 10256.236486486487], [0, 0, [0, 0, 0, 0, 1, 1], 28360.0], [0, 0, [0, 0, 0, 1, 0, 0], 16757.095781071836], [0, 0, [0, 0, 0, 1, 0, 1], 31279.41176470588], 0.0, 0.0, [0, 0, [0, 0, 1, 0, 0, 0], 60125.0], [0, 0, [0, 0, 1, 0, 0, 1], 30636.363636363636], [0, 0, [0, 0, 1, 0, 1, 0], 24481.912280701756], [0, 0, [0, 0, 1, 0, 1, 1], 54076.92307692308], 0.0, 0.0, 0.0, 0.0, [0, 0, [0, 1, 0, 0, 0, 0], 9037.341772151898], [0, 0, [0, 1, 0, 0, 0, 1], 13276.271186440677], [0, 0, [0, 1, 0, 0, 1, 0], 21833.14438502674], [0, 0, [0, 1, 0, 0, 1, 1], 14046.341463414634], [0, 0, [0, 1, 0, 1, 0, 0], 18454.320346320346], [0, 0, [0, 1, 0, 1, 0, 1], 34380.0], [0, 0, [0, 1, 0, 1, 1, 0], 60910.37777777778], [0, 0, [0, 1, 0, 1, 1, 1], 42658.22151898734], [0, 0, [0, 1, 1, 0, 0, 0], 41913.793103448275], [0, 0, [0, 1, 1, 0, 0, 1], 120682.50570342205], [0, 0, [0, 1, 1, 0, 1, 0], 44566.666666666664], [0, 0, [0, 1, 1, 0, 1, 1], 61411.76470588235], 0.0, 0.0, [0, 0, [0, 1, 1, 1, 1, 0], 59968.71875], [0, 0, [0, 1, 1, 1, 1, 1], 106999.92857142857], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 1, 0], 231200.0], [0, 0, [1, 1, 0, 0, 1, 1], 293913.04347826086], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 8\n",
      "the size of d is 14\n",
      "the size of d is 16\n",
      "[[['Carpet Area', 0.5, 0]], [['Kolkata', 0.5, [0]], ['Bathroom', 3.5, [1]]], [['Mumbai', 0.5, [0, 0]], ['Bathroom', 1.5, [0, 1]], ['Unfurnished', 0.5, [1, 0]], ['Mumbai', 0.5, [1, 1]]], [['Bathroom', 2.5, [0, 0, 0]], ['Contact Owner', 0.5, [0, 0, 1]], [0, 0, [0, 1, 0], 7692.602564102564], ['Bathroom', 2.5, [0, 1, 1]], ['Size', 2450.0, [1, 0, 0]], ['Contact Owner', 0.5, [1, 0, 1]], ['Size', 3375.0, [1, 1, 0]], ['Bathroom', 4.5, [1, 1, 1]]], [['Bachelors', 0.5, [0, 0, 0, 0]], ['Size', 2150.0, [0, 0, 0, 1]], [0, 0, [0, 0, 1, 0], 101708.33333333333], ['Semi-Furnished', 0.5, [0, 0, 1, 1]], 0.0, 0.0, ['Size', 1310.0, [0, 1, 1, 0]], [0, 0, [0, 1, 1, 1], 22461.53846153846], ['Contact Owner', 0.5, [1, 0, 0, 0]], [0, 0, [1, 0, 0, 1], 628892.8571428572], ['BHK', 1.5, [1, 0, 1, 0]], ['BHK', 2.5, [1, 0, 1, 1]], [0, 0, [1, 1, 0, 0], 106736.84210526316], [0, 0, [1, 1, 0, 1], 226666.66666666666], ['Furnished', 0.5, [1, 1, 1, 0]], [0, 0, [1, 1, 1, 1], 375750.0]], [['Unfurnished', 0.5, [0, 0, 0, 0, 0]], ['Size', 1013.5, [0, 0, 0, 0, 1]], ['Contact Agent', 0.5, [0, 0, 0, 1, 0]], ['BHK', 3.5, [0, 0, 0, 1, 1]], 0.0, 0.0, ['Furnished', 0.5, [0, 0, 1, 1, 0]], ['Size', 1150.0, [0, 0, 1, 1, 1]], 0.0, 0.0, 0.0, 0.0, ['Unfurnished', 0.5, [0, 1, 1, 0, 0]], [0, 0, [0, 1, 1, 0, 1], 26340.277777777777], 0.0, 0.0, ['Bangalore', 0.5, [1, 0, 0, 0, 0]], ['Bangalore', 0.5, [1, 0, 0, 0, 1]], 0.0, 0.0, ['Bathroom', 1.5, [1, 0, 1, 0, 0]], ['BHK', 2.5, [1, 0, 1, 0, 1]], ['Bathroom', 1.5, [1, 0, 1, 1, 0]], ['Size', 1210.0, [1, 0, 1, 1, 1]], 0.0, 0.0, 0.0, 0.0, ['Size', 1752.5, [1, 1, 1, 0, 0]], [0, 0, [1, 1, 1, 0, 1], 311615.3846153846], 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 14291.371577574968], [0, 0, [0, 0, 0, 0, 0, 1], 11107.98319327731], [0, 0, [0, 0, 0, 0, 1, 0], 12392.156862745098], [0, 0, [0, 0, 0, 0, 1, 1], 30772.727272727272], [0, 0, [0, 0, 0, 1, 0, 0], 30731.12676056338], [0, 0, [0, 0, 0, 1, 0, 1], 49568.96551724138], [0, 0, [0, 0, 0, 1, 1, 0], 77578.94736842105], [0, 0, [0, 0, 0, 1, 1, 1], 111333.33333333333], 0.0, 0.0, 0.0, 0.0, [0, 0, [0, 0, 1, 1, 0, 0], 19038.46153846154], [0, 0, [0, 0, 1, 1, 0, 1], 60515.807692307695], [0, 0, [0, 0, 1, 1, 1, 0], 27618.18181818182], [0, 0, [0, 0, 1, 1, 1, 1], 143769.23076923078], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [0, 1, 1, 0, 0, 0], 13548.387096774193], [0, 0, [0, 1, 1, 0, 0, 1], 10796.875], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 0, 0, 0, 0, 0], 61539.858054226475], [0, 0, [1, 0, 0, 0, 0, 1], 28331.62393162393], [0, 0, [1, 0, 0, 0, 1, 0], 21021.404682274246], [0, 0, [1, 0, 0, 0, 1, 1], 15505.633802816901], 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 0, 1, 0, 0, 0], 15548.192771084337], [0, 0, [1, 0, 1, 0, 0, 1], 30012.79487179487], [0, 0, [1, 0, 1, 0, 1, 0], 41753.97727272727], [0, 0, [1, 0, 1, 0, 1, 1], 59129.41176470588], [0, 0, [1, 0, 1, 1, 0, 0], 10308.641975308641], [0, 0, [1, 0, 1, 1, 0, 1], 19156.55737704918], [0, 0, [1, 0, 1, 1, 1, 0], 20723.684210526317], [0, 0, [1, 0, 1, 1, 1, 1], 35318.181818181816], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 1, 0, 0, 0], 145100.0], [0, 0, [1, 1, 1, 0, 0, 1], 385454.54545454547], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 6\n",
      "the size of d is 10\n",
      "the size of d is 18\n",
      "[[['Contact Agent', 0.5, 0]], [['Bathroom', 3.5, [0]], ['Mumbai', 0.5, [1]]], [['Bathroom', 1.5, [0, 0]], [0, 0, [0, 1], 106687.5], ['Bathroom', 3.5, [1, 0]], ['Size', 1412.5, [1, 1]]], [['Unfurnished', 0.5, [0, 0, 0]], ['Kolkata', 0.5, [0, 0, 1]], 0.0, 0.0, ['BHK', 2.5, [1, 0, 0]], ['Size', 3400.0, [1, 0, 1]], ['Unfurnished', 0.5, [1, 1, 0]], [0, 0, [1, 1, 1], 286601.9417475728]], [['Kolkata', 0.5, [0, 0, 0, 0]], ['BHK', 2.5, [0, 0, 0, 1]], ['BHK', 2.5, [0, 0, 1, 0]], ['Size', 980.0, [0, 0, 1, 1]], 0.0, 0.0, 0.0, 0.0, ['BHK', 1.5, [1, 0, 0, 0]], ['Bathroom', 2.5, [1, 0, 0, 1]], ['Size', 2750.0, [1, 0, 1, 0]], [0, 0, [1, 0, 1, 1], 177647.0588235294], ['BHK', 2.5, [1, 1, 0, 0]], ['BHK', 2.5, [1, 1, 0, 1]], 0.0, 0.0], [['Mumbai', 0.5, [0, 0, 0, 0, 0]], ['BHK', 1.5, [0, 0, 0, 0, 1]], ['Family', 0.5, [0, 0, 0, 1, 0]], [0, 0, [0, 0, 0, 1, 1], 15750.0], ['Carpet Area', 0.5, [0, 0, 1, 0, 0]], ['Size', 1426.5, [0, 0, 1, 0, 1]], ['Size', 819.5, [0, 0, 1, 1, 0]], ['Bachelors', 0.5, [0, 0, 1, 1, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ['Kolkata', 0.5, [1, 0, 0, 0, 0]], ['Bathroom', 1.5, [1, 0, 0, 0, 1]], ['Bachelors', 0.5, [1, 0, 0, 1, 0]], ['Family', 0.5, [1, 0, 0, 1, 1]], [0, 0, [1, 0, 1, 0, 0], 93259.25925925926], [0, 0, [1, 0, 1, 0, 1], 121764.70588235294], 0.0, 0.0, ['Family', 0.5, [1, 1, 0, 0, 0]], [0, 0, [1, 1, 0, 0, 1], 109187.83108108108], [0, 0, [1, 1, 0, 1, 0], 42209.00564971752], ['Size', 931.0, [1, 1, 0, 1, 1]], 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 10084.232432432433], [0, 0, [0, 0, 0, 0, 0, 1], 23350.0], [0, 0, [0, 0, 0, 0, 1, 0], 6893.478260869565], [0, 0, [0, 0, 0, 0, 1, 1], 9848.333333333334], [0, 0, [0, 0, 0, 1, 0, 0], 8835.783882783882], [0, 0, [0, 0, 0, 1, 0, 1], 11847.058823529413], 0.0, 0.0, [0, 0, [0, 0, 1, 0, 0, 0], 16487.5442670537], [0, 0, [0, 0, 1, 0, 0, 1], 22245.07299270073], [0, 0, [0, 0, 1, 0, 1, 0], 20865.424731182797], [0, 0, [0, 0, 1, 0, 1, 1], 36561.068702290075], [0, 0, [0, 0, 1, 1, 0, 0], 9764.0], [0, 0, [0, 0, 1, 1, 0, 1], 13034.48275862069], [0, 0, [0, 0, 1, 1, 1, 0], 19152.439024390245], [0, 0, [0, 0, 1, 1, 1, 1], 15083.333333333334], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 0, 0, 0, 0, 0], 13096.774193548386], [0, 0, [1, 0, 0, 0, 0, 1], 7914.705882352941], [0, 0, [1, 0, 0, 0, 1, 0], 15876.871794871795], [0, 0, [1, 0, 0, 0, 1, 1], 25320.62580645161], [0, 0, [1, 0, 0, 1, 0, 0], 27795.454545454544], [0, 0, [1, 0, 0, 1, 0, 1], 37925.0], [0, 0, [1, 0, 0, 1, 1, 0], 60954.53939393939], [0, 0, [1, 0, 0, 1, 1, 1], 42937.4375], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 0, 0], 60399.58606557377], [0, 0, [1, 1, 0, 0, 0, 1], 39438.553846153845], 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 1, 1, 0], 57833.333333333336], [0, 0, [1, 1, 0, 1, 1, 1], 85529.38235294117], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 8\n",
      "the size of d is 14\n",
      "the size of d is 16\n",
      "[[['BHK', 3.5, 0]], [['Mumbai', 0.5, [0]], ['Contact Owner', 0.5, [1]]], [['Contact Agent', 0.5, [0, 0]], ['Super Area', 0.5, [0, 1]], ['Furnished', 0.5, [1, 0]], ['Size', 1680.0, [1, 1]]], [['Size', 1269.0, [0, 0, 0]], ['BHK', 2.5, [0, 0, 1]], ['Bathroom', 2.5, [0, 1, 0]], ['Furnished', 0.5, [0, 1, 1]], ['Delhi', 0.5, [1, 0, 0]], ['Size', 2160.0, [1, 0, 1]], ['Bathroom', 2.5, [1, 1, 0]], [0, 0, [1, 1, 1], 150863.63636363635]], [['BHK', 1.5, [0, 0, 0, 0]], ['BHK', 2.5, [0, 0, 0, 1]], ['Size', 1181.0, [0, 0, 1, 0]], ['Semi-Furnished', 0.5, [0, 0, 1, 1]], ['BHK', 1.5, [0, 1, 0, 0]], ['Size', 1700.0, [0, 1, 0, 1]], ['Bathroom', 2.5, [0, 1, 1, 0]], [0, 0, [0, 1, 1, 1], 52573.529411764706], ['Semi-Furnished', 0.5, [1, 0, 0, 0]], [0, 0, [1, 0, 0, 1], 126250.0], [0, 0, [1, 0, 1, 0], 229230.76923076922], [0, 0, [1, 0, 1, 1], 321250.0], [0, 0, [1, 1, 0, 0], 15820.133333333333], [0, 0, [1, 1, 0, 1], 46250.0], 0.0, 0.0], [['Size', 605.0, [0, 0, 0, 0, 0]], ['Size', 892.0, [0, 0, 0, 0, 1]], ['Bathroom', 1.5, [0, 0, 0, 1, 0]], ['Size', 1875.0, [0, 0, 0, 1, 1]], ['Bathroom', 1.5, [0, 0, 1, 0, 0]], ['Size', 1265.0, [0, 0, 1, 0, 1]], ['Size', 1956.0, [0, 0, 1, 1, 0]], ['Size', 2250.0, [0, 0, 1, 1, 1]], ['Size', 473.5, [0, 1, 0, 0, 0]], ['BHK', 2.5, [0, 1, 0, 0, 1]], ['Unfurnished', 0.5, [0, 1, 0, 1, 0]], [0, 0, [0, 1, 0, 1, 1], 270000.0], ['BHK', 1.5, [0, 1, 1, 0, 0]], [0, 0, [0, 1, 1, 0, 1], 112194.44444444444], 0.0, 0.0, [0, 0, [1, 0, 0, 0, 0], 121720.0], ['Bathroom', 4.5, [1, 0, 0, 0, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 7795.9876543209875], [0, 0, [0, 0, 0, 0, 0, 1], 10161.739130434782], [0, 0, [0, 0, 0, 0, 1, 0], 11898.034659820283], [0, 0, [0, 0, 0, 0, 1, 1], 17833.89923664122], [0, 0, [0, 0, 0, 1, 0, 0], 13423.076923076924], [0, 0, [0, 0, 0, 1, 0, 1], 21086.720588235294], [0, 0, [0, 0, 0, 1, 1, 0], 27566.729411764707], [0, 0, [0, 0, 0, 1, 1, 1], 54886.36363636364], [0, 0, [0, 0, 1, 0, 0, 0], 11882.454545454546], [0, 0, [0, 0, 1, 0, 0, 1], 20530.398550724636], [0, 0, [0, 0, 1, 0, 1, 0], 29734.9], [0, 0, [0, 0, 1, 0, 1, 1], 39071.42857142857], [0, 0, [0, 0, 1, 1, 0, 0], 44232.394366197186], [0, 0, [0, 0, 1, 1, 0, 1], 88625.0], [0, 0, [0, 0, 1, 1, 1, 0], 41239.85135135135], [0, 0, [0, 0, 1, 1, 1, 1], 97000.0], [0, 0, [0, 1, 0, 0, 0, 0], 25975.984], [0, 0, [0, 1, 0, 0, 0, 1], 42008.91071428572], [0, 0, [0, 1, 0, 0, 1, 0], 61522.36163522013], [0, 0, [0, 1, 0, 0, 1, 1], 96428.57142857143], [0, 0, [0, 1, 0, 1, 0, 0], 118708.04026845637], [0, 0, [0, 1, 0, 1, 0, 1], 81586.5], 0.0, 0.0, [0, 0, [0, 1, 1, 0, 0, 0], 23480.0], [0, 0, [0, 1, 1, 0, 0, 1], 42850.0], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 0, 0, 0, 1, 0], 247666.66666666666], [0, 0, [1, 0, 0, 0, 1, 1], 360645.1612903226], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 6\n",
      "the size of d is 12\n",
      "the size of d is 16\n",
      "[[['Size', 2412.0, 0]], [['Mumbai', 0.5, [0]], ['Furnished', 0.5, [1]]], [['Contact Owner', 0.5, [0, 0]], ['Bathroom', 2.5, [0, 1]], ['Super Area', 0.5, [1, 0]], [0, 0, [1, 1], 374400.0]], [['Bathroom', 2.5, [0, 0, 0]], ['Furnished', 0.5, [0, 0, 1]], ['Size', 707.0, [0, 1, 0]], ['Size', 1327.5, [0, 1, 1]], ['Mumbai', 0.5, [1, 0, 0]], ['Bathroom', 3.5, [1, 0, 1]], 0.0, 0.0], [['Bathroom', 1.5, [0, 0, 0, 0]], ['Bachelors/Family', 0.5, [0, 0, 0, 1]], ['BHK', 2.5, [0, 0, 1, 0]], ['Size', 1850.0, [0, 0, 1, 1]], ['Contact Agent', 0.5, [0, 1, 0, 0]], ['Size', 999.5, [0, 1, 0, 1]], ['Furnished', 0.5, [0, 1, 1, 0]], ['Bathroom', 3.5, [0, 1, 1, 1]], [0, 0, [1, 0, 0, 0], 185267.44186046513], [0, 0, [1, 0, 0, 1], 438571.4285714286], [0, 0, [1, 0, 1, 0], 64727.27272727273], [0, 0, [1, 0, 1, 1], 136363.63636363635], 0.0, 0.0, 0.0, 0.0], [['Size', 377.5, [0, 0, 0, 0, 0]], ['Unfurnished', 0.5, [0, 0, 0, 0, 1]], ['Chennai', 0.5, [0, 0, 0, 1, 0]], ['Super Area', 0.5, [0, 0, 0, 1, 1]], ['BHK', 1.5, [0, 0, 1, 0, 0]], ['Semi-Furnished', 0.5, [0, 0, 1, 0, 1]], ['Size', 827.5, [0, 0, 1, 1, 0]], [0, 0, [0, 0, 1, 1, 1], 83316.16666666667], ['Size', 484.0, [0, 1, 0, 0, 0]], ['Furnished', 0.5, [0, 1, 0, 0, 1]], ['Super Area', 0.5, [0, 1, 0, 1, 0]], [0, 0, [0, 1, 0, 1, 1], 100633.33333333333], ['Semi-Furnished', 0.5, [0, 1, 1, 0, 0]], [0, 0, [0, 1, 1, 0, 1], 101511.04444444444], [0, 0, [0, 1, 1, 1, 0], 145131.1475409836], ['Family', 0.5, [0, 1, 1, 1, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 9403.125], [0, 0, [0, 0, 0, 0, 0, 1], 13686.716814159292], [0, 0, [0, 0, 0, 0, 1, 0], 27763.543209876545], [0, 0, [0, 0, 0, 0, 1, 1], 22703.389830508473], [0, 0, [0, 0, 0, 1, 0, 0], 47338.709677419356], [0, 0, [0, 0, 0, 1, 0, 1], 58300.0], [0, 0, [0, 0, 0, 1, 1, 0], 56356.045454545456], [0, 0, [0, 0, 0, 1, 1, 1], 85525.0], [0, 0, [0, 0, 1, 0, 0, 0], 7916.089965397924], [0, 0, [0, 0, 1, 0, 0, 1], 14118.932287365813], [0, 0, [0, 0, 1, 0, 1, 0], 20417.410714285714], [0, 0, [0, 0, 1, 0, 1, 1], 24054.10546875], [0, 0, [0, 0, 1, 1, 0, 0], 12811.354609929078], [0, 0, [0, 0, 1, 1, 0, 1], 25299.1452991453], 0.0, 0.0, [0, 0, [0, 1, 0, 0, 0, 0], 20250.0], [0, 0, [0, 1, 0, 0, 0, 1], 27474.418604651164], [0, 0, [0, 1, 0, 0, 1, 0], 37360.119266055044], [0, 0, [0, 1, 0, 0, 1, 1], 48440.32835820896], [0, 0, [0, 1, 0, 1, 0, 0], 65280.31914893617], [0, 0, [0, 1, 0, 1, 0, 1], 41269.230769230766], 0.0, 0.0, [0, 0, [0, 1, 1, 0, 0, 0], 61391.89189189189], [0, 0, [0, 1, 1, 0, 0, 1], 96583.33333333333], 0.0, 0.0, 0.0, 0.0, [0, 0, [0, 1, 1, 1, 1, 0], 175000.0], [0, 0, [0, 1, 1, 1, 1, 1], 246363.63636363635], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 8\n",
      "the size of d is 14\n",
      "the size of d is 22\n",
      "[[['Mumbai', 0.5, 0]], [['Bathroom', 2.5, [0]], ['Size', 1477.0, [1]]], [['BHK', 2.5, [0, 0]], ['Contact Owner', 0.5, [0, 1]], ['Contact Owner', 0.5, [1, 0]], ['Super Area', 0.5, [1, 1]]], [['Bathroom', 1.5, [0, 0, 0]], ['Size', 1387.0, [0, 0, 1]], ['BHK', 3.5, [0, 1, 0]], ['Size', 2250.0, [0, 1, 1]], ['Unfurnished', 0.5, [1, 0, 0]], ['Bathroom', 1.5, [1, 0, 1]], ['Family', 0.5, [1, 1, 0]], [0, 0, [1, 1, 1], 179583.33333333334]], [['Unfurnished', 0.5, [0, 0, 0, 0]], ['Size', 945.0, [0, 0, 0, 1]], ['Contact Agent', 0.5, [0, 0, 1, 0]], ['Contact Owner', 0.5, [0, 0, 1, 1]], ['Family', 0.5, [0, 1, 0, 0]], ['Bathroom', 3.5, [0, 1, 0, 1]], ['Size', 1758.5, [0, 1, 1, 0]], [0, 0, [0, 1, 1, 1], 130312.5], ['BHK', 2.5, [1, 0, 0, 0]], ['Bathroom', 2.5, [1, 0, 0, 1]], ['Furnished', 0.5, [1, 0, 1, 0]], [0, 0, [1, 0, 1, 1], 38327.102803738315], ['Size', 2840.0, [1, 1, 0, 0]], [0, 0, [1, 1, 0, 1], 230650.0], 0.0, 0.0], [['Size', 605.0, [0, 0, 0, 0, 0]], ['Delhi', 0.5, [0, 0, 0, 0, 1]], ['Delhi', 0.5, [0, 0, 0, 1, 0]], ['Carpet Area', 0.5, [0, 0, 0, 1, 1]], ['Delhi', 0.5, [0, 0, 1, 0, 0]], ['Size', 1175.0, [0, 0, 1, 0, 1]], ['Size', 1490.0, [0, 0, 1, 1, 0]], ['Semi-Furnished', 0.5, [0, 0, 1, 1, 1]], ['Bangalore', 0.5, [0, 1, 0, 0, 0]], [0, 0, [0, 1, 0, 0, 1], 42833.23809523809], [0, 0, [0, 1, 0, 1, 0], 54363.63636363636], ['Size', 4223.0, [0, 1, 0, 1, 1]], ['Delhi', 0.5, [0, 1, 1, 0, 0]], ['Furnished', 0.5, [0, 1, 1, 0, 1]], 0.0, 0.0, ['Size', 712.5, [1, 0, 0, 0, 0]], ['Bathroom', 2.5, [1, 0, 0, 0, 1]], ['Bathroom', 1.5, [1, 0, 0, 1, 0]], ['Size', 1179.0, [1, 0, 0, 1, 1]], ['Bachelors/Family', 0.5, [1, 0, 1, 0, 0]], [0, 0, [1, 0, 1, 0, 1], 34363.63636363636], 0.0, 0.0, ['Size', 2079.5, [1, 1, 0, 0, 0]], [0, 0, [1, 1, 0, 0, 1], 590000.0], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 10059.015384615384], [0, 0, [0, 0, 0, 0, 0, 1], 12456.202614379084], [0, 0, [0, 0, 0, 0, 1, 0], 7878.922716627635], [0, 0, [0, 0, 0, 0, 1, 1], 10177.777777777777], [0, 0, [0, 0, 0, 1, 0, 0], 12795.04705882353], [0, 0, [0, 0, 0, 1, 0, 1], 17708.625899280574], [0, 0, [0, 0, 0, 1, 1, 0], 17196.66966966967], [0, 0, [0, 0, 0, 1, 1, 1], 25100.59638554217], [0, 0, [0, 0, 1, 0, 0, 0], 18151.1768707483], [0, 0, [0, 0, 1, 0, 0, 1], 23464.945945945947], [0, 0, [0, 0, 1, 0, 1, 0], 23385.714285714286], [0, 0, [0, 0, 1, 0, 1, 1], 29000.0], [0, 0, [0, 0, 1, 1, 0, 0], 47000.0], [0, 0, [0, 0, 1, 1, 0, 1], 39718.75], [0, 0, [0, 0, 1, 1, 1, 0], 30727.272727272728], [0, 0, [0, 0, 1, 1, 1, 1], 23269.23076923077], [0, 0, [0, 1, 0, 0, 0, 0], 49483.333333333336], [0, 0, [0, 1, 0, 0, 0, 1], 163688.40579710144], 0.0, 0.0, 0.0, 0.0, [0, 0, [0, 1, 0, 1, 1, 0], 141974.35897435897], [0, 0, [0, 1, 0, 1, 1, 1], 201818.18181818182], [0, 0, [0, 1, 1, 0, 0, 0], 23553.969512195123], [0, 0, [0, 1, 1, 0, 0, 1], 50000.0], [0, 0, [0, 1, 1, 0, 1, 0], 36648.148148148146], [0, 0, [0, 1, 1, 0, 1, 1], 53933.333333333336], 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 0, 0, 0, 0, 0], 43384.17682926829], [0, 0, [1, 0, 0, 0, 0, 1], 76174.10714285714], [0, 0, [1, 0, 0, 0, 1, 0], 85423.07692307692], [0, 0, [1, 0, 0, 0, 1, 1], 117342.57407407407], [0, 0, [1, 0, 0, 1, 0, 0], 26760.416666666668], [0, 0, [1, 0, 0, 1, 0, 1], 46345.89937106918], [0, 0, [1, 0, 0, 1, 1, 0], 76054.05405405405], [0, 0, [1, 0, 0, 1, 1, 1], 119468.75], [0, 0, [1, 0, 1, 0, 0, 0], 18527.777777777777], [0, 0, [1, 0, 1, 0, 0, 1], 22401.639344262294], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 0, 0], 232466.66666666666], [0, 0, [1, 1, 0, 0, 0, 1], 302857.14285714284], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 6\n",
      "the size of d is 8\n",
      "the size of d is 10\n",
      "[[['Size', 2465.0, 0]], [['Bathroom', 3.5, [0]], ['Size', 2510.0, [1]]], [['Mumbai', 0.5, [0, 0]], ['Bathroom', 4.5, [0, 1]], [0, 0, [1, 0], 1390357.142857143], ['Mumbai', 0.5, [1, 1]]], [['Size', 1435.0, [0, 0, 0]], ['BHK', 2.5, [0, 0, 1]], ['Bachelors/Family', 0.5, [0, 1, 0]], [0, 0, [0, 1, 1], 265625.0], 0.0, 0.0, ['Size', 3550.0, [1, 1, 0]], [0, 0, [1, 1, 1], 491111.1111111111]], [['Size', 944.5, [0, 0, 0, 0]], ['Kolkata', 0.5, [0, 0, 0, 1]], ['Contact Agent', 0.5, [0, 0, 1, 0]], ['Size', 1475.0, [0, 0, 1, 1]], [0, 0, [0, 1, 0, 0], 200000.0], [0, 0, [0, 1, 0, 1], 133025.0], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ['Bathroom', 3.5, [1, 1, 0, 0]], [0, 0, [1, 1, 0, 1], 181944.44444444444], 0.0, 0.0], [['Kolkata', 0.5, [0, 0, 0, 0, 0]], ['Bachelors', 0.5, [0, 0, 0, 0, 1]], ['Bathroom', 2.5, [0, 0, 0, 1, 0]], [0, 0, [0, 0, 0, 1, 1], 22439.655172413793], ['Size', 649.5, [0, 0, 1, 0, 0]], ['Furnished', 0.5, [0, 0, 1, 0, 1]], ['Unfurnished', 0.5, [0, 0, 1, 1, 0]], ['Furnished', 0.5, [0, 0, 1, 1, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 0], 84166.66666666667], [0, 0, [1, 1, 0, 0, 1], 138785.7142857143], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 12051.018854748603], [0, 0, [0, 0, 0, 0, 0, 1], 8166.951898734177], [0, 0, [0, 0, 0, 0, 1, 0], 19074.500821018064], [0, 0, [0, 0, 0, 0, 1, 1], 38929.0780141844], [0, 0, [0, 0, 0, 1, 0, 0], 27837.896551724138], [0, 0, [0, 0, 0, 1, 0, 1], 47093.06060606061], 0.0, 0.0, [0, 0, [0, 0, 1, 0, 0, 0], 25091.192592592593], [0, 0, [0, 0, 1, 0, 0, 1], 46680.0], [0, 0, [0, 0, 1, 0, 1, 0], 47370.55968169761], [0, 0, [0, 0, 1, 0, 1, 1], 71342.57407407407], [0, 0, [0, 0, 1, 1, 0, 0], 104053.57142857143], [0, 0, [0, 0, 1, 1, 0, 1], 74999.96078431372], [0, 0, [0, 0, 1, 1, 1, 0], 161142.85714285713], [0, 0, [0, 0, 1, 1, 1, 1], 244166.66666666666], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 8\n",
      "the size of d is 12\n",
      "the size of d is 18\n",
      "[[['Bathroom', 3.5, 0]], [['Mumbai', 0.5, [0]], ['Carpet Area', 0.5, [1]]], [['Size', 1435.0, [0, 0]], ['Bathroom', 2.5, [0, 1]], ['Size', 1904.0, [1, 0]], ['Size', 3032.0, [1, 1]]], [['Bathroom', 1.5, [0, 0, 0]], ['Bathroom', 2.5, [0, 0, 1]], ['Contact Owner', 0.5, [0, 1, 0]], ['Unfurnished', 0.5, [0, 1, 1]], [0, 0, [1, 0, 0], 73714.28571428571], [0, 0, [1, 0, 1], 142692.3076923077], ['Delhi', 0.5, [1, 1, 0]], ['Mumbai', 0.5, [1, 1, 1]]], [['Contact Owner', 0.5, [0, 0, 0, 0]], ['Contact Owner', 0.5, [0, 0, 0, 1]], ['Contact Agent', 0.5, [0, 0, 1, 0]], ['Contact Agent', 0.5, [0, 0, 1, 1]], ['Size', 997.0, [0, 1, 0, 0]], ['BHK', 1.5, [0, 1, 0, 1]], ['Bachelors', 0.5, [0, 1, 1, 0]], ['Bachelors/Family', 0.5, [0, 1, 1, 1]], 0.0, 0.0, 0.0, 0.0, ['Size', 1777.5, [1, 1, 0, 0]], [0, 0, [1, 1, 0, 1], 96461.53846153847], [0, 0, [1, 1, 1, 0], 165950.0], [0, 0, [1, 1, 1, 1], 659166.6666666666]], [['Super Area', 0.5, [0, 0, 0, 0, 0]], ['Size', 840.0, [0, 0, 0, 0, 1]], ['Bathroom', 2.5, [0, 0, 0, 1, 0]], ['Bachelors', 0.5, [0, 0, 0, 1, 1]], ['Semi-Furnished', 0.5, [0, 0, 1, 0, 0]], [0, 0, [0, 0, 1, 0, 1], 39483.333333333336], ['Size', 1832.5, [0, 0, 1, 1, 0]], ['Bachelors', 0.5, [0, 0, 1, 1, 1]], ['Unfurnished', 0.5, [0, 1, 0, 0, 0]], [0, 0, [0, 1, 0, 0, 1], 135125.0], ['Unfurnished', 0.5, [0, 1, 0, 1, 0]], [0, 0, [0, 1, 0, 1, 1], 41858.49056603773], [0, 0, [0, 1, 1, 0, 0], 120771.968], [0, 0, [0, 1, 1, 0, 1], 144117.64705882352], [0, 0, [0, 1, 1, 1, 0], 64166.555555555555], [0, 0, [0, 1, 1, 1, 1], 84304.34782608696], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ['Size', 1522.5, [1, 1, 0, 0, 0]], ['Mumbai', 0.5, [1, 1, 0, 0, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 13819.076335877862], [0, 0, [0, 0, 0, 0, 0, 1], 9574.074074074075], [0, 0, [0, 0, 0, 0, 1, 0], 8755.814109742441], [0, 0, [0, 0, 0, 0, 1, 1], 12621.052631578947], [0, 0, [0, 0, 0, 1, 0, 0], 22549.490384615383], [0, 0, [0, 0, 0, 1, 0, 1], 47860.0], [0, 0, [0, 0, 0, 1, 1, 0], 16089.11403508772], [0, 0, [0, 0, 0, 1, 1, 1], 28626.896551724138], [0, 0, [0, 0, 1, 0, 0, 0], 20729.166666666668], [0, 0, [0, 0, 1, 0, 0, 1], 25158.536585365855], 0.0, 0.0, [0, 0, [0, 0, 1, 1, 0, 0], 31386.84705882353], [0, 0, [0, 0, 1, 1, 0, 1], 51222.22222222222], [0, 0, [0, 0, 1, 1, 1, 0], 56697.63953488372], [0, 0, [0, 0, 1, 1, 1, 1], 64275.362318840576], [0, 0, [0, 1, 0, 0, 0, 0], 56522.6690647482], [0, 0, [0, 1, 0, 0, 0, 1], 38222.41818181818], 0.0, 0.0, [0, 0, [0, 1, 0, 1, 0, 0], 22622.22033898305], [0, 0, [0, 1, 0, 1, 0, 1], 20439.024390243903], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 0, 0], 124280.0], [0, 0, [1, 1, 0, 0, 0, 1], 199600.0], [0, 0, [1, 1, 0, 0, 1, 0], 82736.84210526316], [0, 0, [1, 1, 0, 0, 1, 1], 340526.3157894737], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hope youve inputted the max_features option as a decimal percentage\n",
      "the size of d is 2\n",
      "the size of d is 4\n",
      "the size of d is 6\n",
      "the size of d is 12\n",
      "the size of d is 18\n",
      "[[['Bathroom', 3.5, 0]], [['Contact Owner', 0.5, [0]], ['Carpet Area', 0.5, [1]]], [['Size', 802.5, [0, 0]], ['Delhi', 0.5, [0, 1]], [0, 0, [1, 0], 131750.0], ['Delhi', 0.5, [1, 1]]], [['Mumbai', 0.5, [0, 0, 0]], ['Bathroom', 2.5, [0, 0, 1]], ['Bathroom', 1.5, [0, 1, 0]], ['Size', 1725.0, [0, 1, 1]], 0.0, 0.0, ['Unfurnished', 0.5, [1, 1, 0]], ['Size', 2750.0, [1, 1, 1]]], [['BHK', 2.5, [0, 0, 0, 0]], ['Furnished', 0.5, [0, 0, 0, 1]], ['Furnished', 0.5, [0, 0, 1, 0]], ['Delhi', 0.5, [0, 0, 1, 1]], ['Mumbai', 0.5, [0, 1, 0, 0]], ['Bathroom', 2.5, [0, 1, 0, 1]], ['BHK', 2.5, [0, 1, 1, 0]], [0, 0, [0, 1, 1, 1], 89500.0], 0.0, 0.0, 0.0, 0.0, ['BHK', 3.5, [1, 1, 0, 0]], ['Size', 2450.0, [1, 1, 0, 1]], [0, 0, [1, 1, 1, 0], 56818.181818181816], [0, 0, [1, 1, 1, 1], 198181.81818181818]], [['Size', 605.0, [0, 0, 0, 0, 0]], [0, 0, [0, 0, 0, 0, 1], 46275.0], ['Bathroom', 1.5, [0, 0, 0, 1, 0]], ['Family', 0.5, [0, 0, 0, 1, 1]], ['Mumbai', 0.5, [0, 0, 1, 0, 0]], ['Bachelors', 0.5, [0, 0, 1, 0, 1]], ['Mumbai', 0.5, [0, 0, 1, 1, 0]], [0, 0, [0, 0, 1, 1, 1], 53607.8431372549], ['Semi-Furnished', 0.5, [0, 1, 0, 0, 0]], ['Bachelors', 0.5, [0, 1, 0, 0, 1]], ['Mumbai', 0.5, [0, 1, 0, 1, 0]], ['Size', 1391.5, [0, 1, 0, 1, 1]], ['Bathroom', 1.5, [0, 1, 1, 0, 0]], ['Size', 117.5, [0, 1, 1, 0, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 0], 176034.4827586207], ['Furnished', 0.5, [1, 1, 0, 0, 1]], [0, 0, [1, 1, 0, 1, 0], 123000.0], [0, 0, [1, 1, 0, 1, 1], 220272.72727272726], 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 12495.031055900621], [0, 0, [0, 0, 0, 0, 0, 1], 18066.583333333332], 0.0, 0.0, [0, 0, [0, 0, 0, 1, 0, 0], 30349.31506849315], [0, 0, [0, 0, 0, 1, 0, 1], 43532.35294117647], [0, 0, [0, 0, 0, 1, 1, 0], 65425.66216216216], [0, 0, [0, 0, 0, 1, 1, 1], 42964.28571428572], [0, 0, [0, 0, 1, 0, 0, 0], 24563.492063492064], [0, 0, [0, 0, 1, 0, 0, 1], 83314.48387096774], [0, 0, [0, 0, 1, 0, 1, 0], 78000.0], [0, 0, [0, 0, 1, 0, 1, 1], 62900.0], [0, 0, [0, 0, 1, 1, 0, 0], 79737.40287769784], [0, 0, [0, 0, 1, 1, 0, 1], 121910.10112359551], 0.0, 0.0, [0, 0, [0, 1, 0, 0, 0, 0], 7975.504098360656], [0, 0, [0, 1, 0, 0, 0, 1], 9683.073619631901], [0, 0, [0, 1, 0, 0, 1, 0], 22151.08695652174], [0, 0, [0, 1, 0, 0, 1, 1], 16115.384615384615], [0, 0, [0, 1, 0, 1, 0, 0], 16181.701612903225], [0, 0, [0, 1, 0, 1, 0, 1], 37393.96296296296], [0, 0, [0, 1, 0, 1, 1, 0], 18448.051948051947], [0, 0, [0, 1, 0, 1, 1, 1], 34575.757575757576], [0, 0, [0, 1, 1, 0, 0, 0], 11604.419889502762], [0, 0, [0, 1, 1, 0, 0, 1], 19145.833333333332], [0, 0, [0, 1, 1, 0, 1, 0], 12333.333333333334], [0, 0, [0, 1, 1, 0, 1, 1], 27358.695652173912], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 1, 0, 0, 1, 0], 329521.73913043475], [0, 0, [1, 1, 0, 0, 1, 1], 281666.6666666667], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "[[['Bathroom', 3.5, 0]], [['Bathroom', 2.5, [0]], ['Mumbai', 0.5, [1]]], [['Bathroom', 1.5, [0, 0]], ['Contact Agent', 0.5, [0, 1]], ['Bangalore', 0.5, [1, 0]], [0, 0, [1, 1], 251709.67741935485]], [['Kolkata', 0.5, [0, 0, 0]], ['Chennai', 0.5, [0, 0, 1]], ['Unfurnished', 0.5, [0, 1, 0]], ['Family', 0.5, [0, 1, 1]], ['Bachelors/Family', 0.5, [1, 0, 0]], ['Size', 3000.0, [1, 0, 1]], 0.0, 0.0], [['Contact Owner', 0.5, [0, 0, 0, 0]], ['Size', 690.0, [0, 0, 0, 1]], ['Bangalore', 0.5, [0, 0, 1, 0]], ['Bachelors', 0.5, [0, 0, 1, 1]], ['Delhi', 0.5, [0, 1, 0, 0]], ['Size', 1550.0, [0, 1, 0, 1]], ['Size', 2465.0, [0, 1, 1, 0]], ['Carpet Area', 0.5, [0, 1, 1, 1]], [0, 0, [1, 0, 0, 0], 102440.0], ['Delhi', 0.5, [1, 0, 0, 1]], [0, 0, [1, 0, 1, 0], 95250.0], [0, 0, [1, 0, 1, 1], 177090.9090909091], 0.0, 0.0, 0.0, 0.0], [['Mumbai', 0.5, [0, 0, 0, 0, 0]], ['Furnished', 0.5, [0, 0, 0, 0, 1]], ['Size', 515.0, [0, 0, 0, 1, 0]], ['Furnished', 0.5, [0, 0, 0, 1, 1]], ['Contact Owner', 0.5, [0, 0, 1, 0, 0]], ['Size', 1225.0, [0, 0, 1, 0, 1]], ['Contact Agent', 0.5, [0, 0, 1, 1, 0]], ['Semi-Furnished', 0.5, [0, 0, 1, 1, 1]], ['Size', 1419.0, [0, 1, 0, 0, 0]], [0, 0, [0, 1, 0, 0, 1], 57800.0], [0, 0, [0, 1, 0, 1, 0], 19777.777777777777], [0, 0, [0, 1, 0, 1, 1], 31000.0], ['Delhi', 0.5, [0, 1, 1, 0, 0]], [0, 0, [0, 1, 1, 0, 1], 555000.0], [0, 0, [0, 1, 1, 1, 0], 39909.09090909091], [0, 0, [0, 1, 1, 1, 1], 82782.98113207547], 0.0, 0.0, [0, 0, [1, 0, 0, 1, 0], 105318.18181818182], ['Size', 2650.0, [1, 0, 0, 1, 1]], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [[0, 0, [0, 0, 0, 0, 0, 0], 14285.067164179105], [0, 0, [0, 0, 0, 0, 0, 1], 37329.78723404255], [0, 0, [0, 0, 0, 0, 1, 0], 10469.471488178026], [0, 0, [0, 0, 0, 0, 1, 1], 16686.04651162791], [0, 0, [0, 0, 0, 1, 0, 0], 5707.194244604317], [0, 0, [0, 0, 0, 1, 0, 1], 7701.666666666667], [0, 0, [0, 0, 0, 1, 1, 0], 10448.574074074075], [0, 0, [0, 0, 0, 1, 1, 1], 13250.0], [0, 0, [0, 0, 1, 0, 0, 0], 50097.10810810811], [0, 0, [0, 0, 1, 0, 0, 1], 21726.170833333334], [0, 0, [0, 0, 1, 0, 1, 0], 16669.843949044585], [0, 0, [0, 0, 1, 0, 1, 1], 28753.846153846152], [0, 0, [0, 0, 1, 1, 0, 0], 14870.262755102041], [0, 0, [0, 0, 1, 1, 0, 1], 25257.085714285713], [0, 0, [0, 0, 1, 1, 1, 0], 50802.32558139535], [0, 0, [0, 0, 1, 1, 1, 1], 19593.75], [0, 0, [0, 1, 0, 0, 0, 0], 24209.677419354837], [0, 0, [0, 1, 0, 0, 0, 1], 34312.87234042553], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [0, 1, 1, 0, 0, 0], 90191.94642857143], [0, 0, [0, 1, 1, 0, 0, 1], 50816.666666666664], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [0, 0, [1, 0, 0, 1, 1, 0], 73181.81818181818], [0, 0, [1, 0, 0, 1, 1, 1], 203090.9090909091], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "tree=random_forest(train, 'Rent', 10, 5, 0.33, 10)\n",
    "print(tree[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad650612",
   "metadata": {},
   "source": [
    "## Predictions 2\n",
    "Now it is time to make a predictions for the target columns of the test data set by using each decision tree in the random forest and taking an average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5117940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_predict(data, tree):\n",
    "    n=0\n",
    "    start=len(data.columns)\n",
    "    for i in tree:\n",
    "        name='prediction_{}'.format(str(n))\n",
    "        n+=1\n",
    "        data=predict(data, i, name)\n",
    "    preds=data.iloc[:,start:]\n",
    "    data['final_predictions']=preds.T.mean().round(1).tolist()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b97e8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearly=forest_predict(test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82e02e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        3078.7\n",
      "1       -7158.1\n",
      "2      -10300.1\n",
      "3       -1062.9\n",
      "4      115078.7\n",
      "5       -6921.3\n",
      "6       -5093.7\n",
      "7       -5340.4\n",
      "8       -3934.2\n",
      "9        8659.6\n",
      "10       -514.9\n",
      "11       3443.8\n",
      "12      -3339.0\n",
      "13      -1062.9\n",
      "14      -7801.0\n",
      "15      -6584.3\n",
      "16       7699.0\n",
      "17      -4084.3\n",
      "18       -454.9\n",
      "19      -3340.4\n",
      "20     -17204.0\n",
      "21     -12099.8\n",
      "22      -7724.7\n",
      "23       -657.4\n",
      "24      -4301.0\n",
      "25      -6975.7\n",
      "26      -5239.6\n",
      "27       2078.7\n",
      "28      -2608.8\n",
      "29      -9594.2\n",
      "30      -2456.7\n",
      "31       1665.2\n",
      "32      -4657.4\n",
      "33      -1975.7\n",
      "34     -14300.1\n",
      "35       3342.6\n",
      "36         78.7\n",
      "37      -6657.4\n",
      "38     -17204.0\n",
      "39        615.4\n",
      "40      -6421.3\n",
      "41     -60030.2\n",
      "42      -1950.6\n",
      "43      -5562.9\n",
      "44      -5921.3\n",
      "45       1836.4\n",
      "46       2485.1\n",
      "47      -7513.4\n",
      "48       4905.5\n",
      "49      -5921.3\n",
      "50      -1231.0\n",
      "51      -4921.3\n",
      "52      -4657.4\n",
      "53      -2982.6\n",
      "54       5915.7\n",
      "55       3906.3\n",
      "56     -89510.7\n",
      "57     -18228.9\n",
      "58       1078.7\n",
      "59      12293.6\n",
      "60      -1657.4\n",
      "61      -5223.4\n",
      "62      11349.6\n",
      "63       2836.4\n",
      "64       6906.3\n",
      "65      -3601.5\n",
      "66      -7120.8\n",
      "67     -32587.5\n",
      "68      -4975.7\n",
      "69      -9266.7\n",
      "70      -8863.1\n",
      "71    -108265.1\n",
      "72       3441.9\n",
      "73      -8961.2\n",
      "74      -8975.7\n",
      "75      -7095.0\n",
      "76     -44683.6\n",
      "77      -2132.9\n",
      "78     -16431.7\n",
      "79      -1093.7\n",
      "80      -3108.8\n",
      "81       3089.0\n",
      "82       2665.2\n",
      "83       2671.5\n",
      "84      -2731.0\n",
      "85      -5657.4\n",
      "86       8024.3\n",
      "87     -15460.3\n",
      "88     -20490.3\n",
      "89      -5713.4\n",
      "90     -17456.7\n",
      "91      -7971.6\n",
      "92      -3301.0\n",
      "93       4263.2\n",
      "94       -975.7\n",
      "95      -2961.2\n",
      "96      -6644.7\n",
      "97     -66305.7\n",
      "98      -6657.4\n",
      "99      -2921.3\n",
      "100     -5387.3\n",
      "101    -11237.3\n",
      "102    -10237.3\n",
      "103     -1361.6\n",
      "104    -13513.4\n",
      "105     -3657.4\n",
      "106    -10741.2\n",
      "107     -1975.7\n",
      "108     -3831.0\n",
      "109    -15546.2\n",
      "110     -8302.6\n",
      "111     -8475.7\n",
      "112     -8423.8\n",
      "113    -12144.6\n",
      "114     -8921.3\n",
      "115     -2975.7\n",
      "116        78.7\n",
      "117    -20819.9\n",
      "118     -3040.9\n",
      "119      -334.8\n",
      "120     -4975.7\n",
      "121     -4657.4\n",
      "122     -6239.6\n",
      "123    -43009.4\n",
      "124     -1184.6\n",
      "125     -5184.6\n",
      "126    -21973.6\n",
      "127     -6541.8\n",
      "128     -5921.3\n",
      "129    -73747.7\n",
      "130     -1731.0\n",
      "131     -4998.1\n",
      "132     -3301.0\n",
      "133     -5191.7\n",
      "134     -1093.7\n",
      "135     -4187.3\n",
      "136     -5833.2\n",
      "137     -7614.6\n",
      "138     -1657.4\n",
      "139     -4975.7\n",
      "140   -108175.6\n",
      "141     -2731.0\n",
      "142       915.7\n",
      "143    -12456.7\n",
      "144    -10487.6\n",
      "145     -7741.2\n",
      "146     -4475.7\n",
      "147     -5725.4\n",
      "148       -62.9\n",
      "149        24.3\n",
      "150     -2974.8\n",
      "151     -1397.6\n",
      "152     -6455.8\n",
      "153    -17288.3\n",
      "154     -6157.4\n",
      "155     -1261.5\n",
      "156     -4520.2\n",
      "157    -12405.3\n",
      "158    -13556.2\n",
      "159     -4975.7\n",
      "160     -2921.3\n",
      "161    -75295.7\n",
      "162     -3431.7\n",
      "163     -3231.0\n",
      "164     -4157.4\n",
      "165    -81458.8\n",
      "166     -8108.8\n",
      "167      4699.0\n",
      "168      -919.0\n",
      "169      -921.3\n",
      "170     -5421.3\n",
      "171     -4701.4\n",
      "172    -14614.6\n",
      "173    -12144.6\n",
      "174     -4921.3\n",
      "175     -8961.2\n",
      "176    -66981.9\n",
      "177     -3731.0\n",
      "178     -1239.6\n",
      "179     -5239.6\n",
      "180     -6982.6\n",
      "181     -1921.3\n",
      "182     -1127.3\n",
      "183      2293.6\n",
      "184     -2562.9\n",
      "185     82093.2\n",
      "186     -6998.1\n",
      "187     -9498.1\n",
      "188     -5725.4\n",
      "189     -8323.0\n",
      "190     -7108.8\n",
      "191     -2793.7\n",
      "192     -4324.4\n",
      "193       397.5\n",
      "194      -975.7\n",
      "195     -4520.2\n",
      "196    -13541.7\n",
      "197     -1602.5\n",
      "198      4359.1\n",
      "199     -3859.4\n",
      "200     -6239.6\n",
      "201     -9427.4\n",
      "202     -1431.7\n",
      "203    -15704.0\n",
      "204     -8204.0\n",
      "205     -6014.9\n",
      "206     -3833.2\n",
      "207     -3323.0\n",
      "208     -9704.0\n",
      "209    -31795.7\n",
      "210     -6975.7\n",
      "211     -2239.6\n",
      "212     -9657.4\n",
      "213     -9934.2\n",
      "214     -9157.4\n",
      "215     -1975.7\n",
      "216     -1231.0\n",
      "217    -22490.3\n",
      "218     -7135.1\n",
      "219     -5638.2\n",
      "220     -7062.9\n",
      "221     -4801.0\n",
      "222    -24397.6\n",
      "223       915.7\n",
      "224    -26397.6\n",
      "225   -146788.2\n",
      "226     -5390.8\n",
      "227     -1975.7\n",
      "228     -5921.3\n",
      "229     -2657.4\n",
      "230     -5657.4\n",
      "231     -6982.6\n",
      "232     -7288.3\n",
      "233     -8998.1\n",
      "234      2743.7\n",
      "235      8906.3\n",
      "236    -11742.1\n",
      "237      -657.4\n",
      "238     -6921.3\n",
      "239     -1239.6\n",
      "240     -6982.6\n",
      "241    -23763.4\n",
      "242      -975.7\n",
      "243     -3231.0\n",
      "244     -1144.6\n",
      "245     -7915.9\n",
      "246      2224.3\n",
      "247    -11559.7\n",
      "248     -4475.7\n",
      "249    -12456.7\n",
      "250     -7725.4\n",
      "251     -8059.7\n",
      "252    -14614.6\n",
      "253    -10657.4\n",
      "254     -8228.9\n",
      "255      1528.4\n",
      "256     -2906.4\n",
      "257     -7421.3\n",
      "258      1937.1\n",
      "259     -1975.7\n",
      "260       260.4\n",
      "261      2179.6\n",
      "262     -8184.6\n",
      "263     -1657.4\n",
      "264    -17248.1\n",
      "265    -18228.9\n",
      "266    -11431.7\n",
      "267     -8059.7\n",
      "268      6906.3\n",
      "269     -7684.6\n",
      "270     -8421.3\n",
      "271       459.1\n",
      "272     -3231.0\n",
      "273     -3820.4\n",
      "274    -28288.3\n",
      "275     -4759.3\n",
      "276       915.7\n",
      "277     -6971.6\n",
      "278     -6471.6\n",
      "279    -36397.6\n",
      "280     -3951.2\n",
      "281    -21397.6\n",
      "282     -6921.3\n",
      "283      8024.3\n",
      "284    -12341.7\n",
      "285      -184.6\n",
      "286     -9431.7\n",
      "287     -1975.7\n",
      "288      -239.6\n",
      "289     -4921.3\n",
      "290    -12237.3\n",
      "291     -7921.3\n",
      "292     -1657.4\n",
      "293     -5421.3\n",
      "294     -3562.9\n",
      "295       695.7\n",
      "296     -1304.3\n",
      "297     -5931.0\n",
      "298      1665.2\n",
      "299      4166.8\n",
      "300     -2921.3\n",
      "301       654.8\n",
      "302    -72099.8\n",
      "303     -8419.0\n",
      "304      -731.0\n",
      "305     -1403.6\n",
      "306     -1231.0\n",
      "307     -8863.1\n",
      "308     -9362.7\n",
      "309     11906.3\n",
      "310     -6657.4\n",
      "311    -13484.9\n",
      "312      1937.1\n",
      "313    -10184.6\n",
      "314     -8209.1\n",
      "315       443.8\n",
      "316     17906.3\n",
      "317        24.3\n",
      "318    -11556.2\n",
      "319      -231.0\n",
      "320     -5421.3\n",
      "321     -9657.4\n",
      "322     -3573.8\n",
      "323      1406.3\n",
      "324      6906.3\n",
      "325     -5987.5\n",
      "326     -1301.0\n",
      "327     -1471.6\n",
      "328     -3657.4\n",
      "329     -4982.6\n",
      "330     -2921.3\n",
      "331     -9475.7\n",
      "332     -2108.8\n",
      "333    -96069.5\n",
      "334    -12843.0\n",
      "335     -4423.8\n",
      "336    -13502.9\n",
      "337    -14931.7\n",
      "338    -19938.7\n",
      "339     -4136.2\n",
      "340     -4062.9\n",
      "341     -8499.4\n",
      "342     -9469.7\n",
      "343     -4975.7\n",
      "344     -4248.1\n",
      "345    -17946.1\n",
      "346     -6657.4\n",
      "347     -7657.4\n",
      "348    -12423.8\n",
      "349     -8657.4\n",
      "350    -93747.7\n",
      "351     -6921.3\n",
      "352    -10684.6\n",
      "353     -7739.6\n",
      "354     -5334.8\n",
      "355     -4248.1\n",
      "356     -2562.9\n",
      "357     -4657.4\n",
      "358     -1475.7\n",
      "359      2659.6\n",
      "360     -2062.9\n",
      "361     -4897.0\n",
      "362     -4345.2\n",
      "363     -6975.7\n",
      "364     -2706.4\n",
      "365     -5225.4\n",
      "366      1342.6\n",
      "367     -4292.4\n",
      "368   -115621.8\n",
      "369     -6204.0\n",
      "370     20593.0\n",
      "371     -3657.4\n",
      "372     -7084.3\n",
      "373     -3431.7\n",
      "374     -2300.1\n",
      "375    -11863.1\n",
      "376      8857.0\n",
      "377      5557.2\n",
      "378     -2102.5\n",
      "379      -754.4\n",
      "380    -23739.3\n",
      "381      -540.9\n",
      "382     -5025.0\n",
      "383      1342.6\n",
      "384     -6556.2\n",
      "385      -839.0\n",
      "386     -3767.8\n",
      "387     -4975.7\n",
      "388     -3333.2\n",
      "389      6497.5\n",
      "390    -10059.7\n",
      "391     -6363.1\n",
      "392    -10977.0\n",
      "393     -8934.2\n",
      "394      3661.0\n",
      "395      6906.3\n",
      "396     -7658.1\n",
      "397     -7301.0\n",
      "398    -27805.5\n",
      "399      -502.9\n",
      "400      2887.5\n",
      "401      2497.5\n",
      "402     -6975.7\n",
      "403     -4921.3\n",
      "404     -8419.0\n",
      "405      2897.6\n",
      "406     -3975.7\n",
      "407     -6921.3\n",
      "408     36581.0\n",
      "409   -107545.8\n",
      "410      9293.6\n",
      "411     -9431.7\n",
      "412    -10498.1\n",
      "413     -6502.5\n",
      "414    -17204.0\n",
      "415     -7062.9\n",
      "416      1252.0\n",
      "417     -6971.6\n",
      "418    -58114.7\n",
      "419     -4975.7\n",
      "420     -7239.6\n",
      "421     -5921.3\n",
      "422     -8093.7\n",
      "423      8751.7\n",
      "424     -3167.8\n",
      "425    -32165.3\n",
      "426     -7204.0\n",
      "427       342.4\n",
      "428     -3231.0\n",
      "429     -1657.4\n",
      "430    -16155.2\n",
      "431     -3231.0\n",
      "432     -5239.6\n",
      "433    -29631.4\n",
      "434     -2763.7\n",
      "435     -1239.6\n",
      "436      -261.5\n",
      "437     -2231.0\n",
      "438     -8657.4\n",
      "439     -1340.4\n",
      "440     -4657.4\n",
      "441    -16122.3\n",
      "442     -7907.5\n",
      "443     -2731.0\n",
      "444      8342.6\n",
      "445     -3239.6\n",
      "446      -102.5\n",
      "447    -10725.4\n",
      "448      4760.4\n",
      "449     -6833.2\n",
      "450      4224.3\n",
      "451    -15931.7\n",
      "452     -6482.6\n",
      "453     -3475.7\n",
      "454     -3231.0\n",
      "455      -108.8\n",
      "456      -863.1\n",
      "457    187422.1\n",
      "458     -2974.1\n",
      "459     -1431.7\n",
      "460     -3040.9\n",
      "461     -4334.8\n",
      "462      6234.8\n",
      "463     -1657.4\n",
      "464    -11451.6\n",
      "465    -12724.7\n",
      "466     -4657.4\n",
      "467     -2239.6\n",
      "468     -4921.3\n",
      "469     -1975.7\n",
      "470    -27805.5\n",
      "471      -540.9\n",
      "472     -3340.4\n",
      "473     -8421.3\n",
      "474    -62244.0\n",
      "475    -86211.2\n",
      "476     -2921.3\n",
      "477    -44850.1\n",
      "478     -3184.6\n",
      "479    -98504.8\n",
      "480      -239.6\n",
      "481     -1975.7\n",
      "482     -8657.4\n",
      "483     -2731.0\n",
      "484      5024.3\n",
      "485     -3031.0\n",
      "486     -2003.4\n",
      "487    -13237.3\n",
      "488     -1975.7\n",
      "489     -7423.8\n",
      "490     -6231.8\n",
      "491     -2740.9\n",
      "492     -4231.0\n",
      "493     -7759.3\n",
      "494     -3239.6\n",
      "495     -3833.2\n",
      "496       -93.7\n",
      "497     -6431.7\n",
      "498     -1951.2\n",
      "499     -8431.7\n",
      "500     -6157.4\n",
      "501      5568.3\n",
      "502     -3184.6\n",
      "503     -6431.7\n",
      "504     -2657.4\n",
      "505     -1406.4\n",
      "506     -4475.7\n",
      "507      3207.0\n",
      "508      2796.0\n",
      "509     -5366.4\n",
      "510     -2062.9\n",
      "511     -7921.3\n",
      "512     -4562.9\n",
      "513     -4231.0\n",
      "514     -8475.7\n",
      "515     -5955.5\n",
      "516      1222.1\n",
      "517     -7739.6\n",
      "518    -94944.0\n",
      "519    -18122.3\n",
      "520     15309.5\n",
      "521    -17122.3\n",
      "522    -17604.6\n",
      "523    -50331.6\n",
      "524     -9998.1\n",
      "525     -4239.6\n",
      "526     -9121.3\n",
      "527     -2076.7\n",
      "528     -6124.2\n",
      "529    -17288.3\n",
      "530    -11397.6\n",
      "531     -1112.5\n",
      "532       405.8\n",
      "533     -9482.6\n",
      "534     -6556.2\n",
      "535     -7559.7\n",
      "536    -11513.4\n",
      "537     -7739.6\n",
      "538    -20288.3\n",
      "539     -3553.0\n",
      "540      6911.1\n",
      "541    -10499.4\n",
      "542       342.4\n",
      "543     22934.6\n",
      "544      1248.3\n",
      "545     15577.2\n",
      "546      6090.4\n",
      "547     -9921.3\n",
      "548      9135.8\n",
      "549     -2231.0\n",
      "550     -6916.7\n",
      "551      4697.4\n",
      "552    -10863.1\n",
      "553    -57478.1\n",
      "554    -24385.7\n",
      "555     -4921.3\n",
      "556     -3129.7\n",
      "557     -5833.2\n",
      "558     -9502.9\n",
      "559      2906.3\n",
      "560     -7035.5\n",
      "561     -1804.3\n",
      "562     -2602.5\n",
      "563     -7739.6\n",
      "564     -7961.2\n",
      "565     -5975.7\n",
      "566    -15228.9\n",
      "567     -5657.4\n",
      "568     -2062.9\n",
      "569     -3657.4\n",
      "570     -4863.1\n",
      "571      -975.7\n",
      "572     -4975.7\n",
      "573       915.7\n",
      "574     -1987.5\n",
      "575    -12288.3\n",
      "576     -7419.8\n",
      "577      4947.0\n",
      "578      1232.2\n",
      "579     -2677.7\n",
      "580     -6323.0\n",
      "581      5443.8\n",
      "582     -9014.9\n",
      "583     -5998.1\n",
      "584     -1845.2\n",
      "585     -1657.4\n",
      "586     -5231.0\n",
      "587     -8340.4\n",
      "588     -4890.8\n",
      "589     -3471.6\n",
      "590     -6431.7\n",
      "591    -26846.2\n",
      "592      3065.8\n",
      "593      2387.5\n",
      "594     -2961.2\n",
      "595    -25061.7\n",
      "596    -22061.7\n",
      "597    -17061.7\n",
      "598    -18061.7\n",
      "599     -1657.4\n",
      "600    -25360.9\n",
      "601     -4975.7\n",
      "602     -8657.4\n",
      "603    -66808.9\n",
      "604      1387.5\n",
      "605     -3231.0\n",
      "606     -8593.7\n",
      "607       769.0\n",
      "608    -14736.8\n",
      "609      3342.6\n",
      "610     -8998.1\n",
      "611     -5998.1\n",
      "612     -5423.8\n",
      "613     -4084.3\n",
      "614     -8093.7\n",
      "615      -775.7\n",
      "616     -5573.8\n",
      "617        -3.4\n",
      "618     -1731.0\n",
      "619      4665.2\n",
      "620     -1731.0\n",
      "621     -5657.4\n",
      "622     -3093.7\n",
      "623     -3588.9\n",
      "624     -5062.9\n",
      "625    -63090.8\n",
      "626      -731.0\n",
      "627     -7975.7\n",
      "628     -1975.7\n",
      "629      3342.6\n",
      "630     -6225.4\n",
      "631     -9961.2\n",
      "632      1769.0\n",
      "633     -3102.5\n",
      "634        78.7\n",
      "635    -80780.8\n",
      "636     -4231.0\n",
      "637     -3231.0\n",
      "638     -1762.9\n",
      "639     -5385.0\n",
      "640     -7725.4\n",
      "641     -6833.2\n",
      "642     -6254.4\n",
      "643       760.4\n",
      "644   -146788.2\n",
      "645    -10256.3\n",
      "646     -2475.7\n",
      "647     -1231.0\n",
      "648    -58826.6\n",
      "649     -6102.4\n",
      "650      2823.6\n",
      "651    -10505.4\n",
      "652     -1731.0\n",
      "653     -5286.2\n",
      "654     -4231.0\n",
      "655     -6982.6\n",
      "656     -2093.7\n",
      "657     -9341.7\n",
      "658     -4062.9\n",
      "659       568.3\n",
      "660    -44397.6\n",
      "661     -9474.8\n",
      "662      1867.1\n",
      "663     -7541.8\n",
      "664     -3975.7\n",
      "665      3342.6\n",
      "666      -102.5\n",
      "667     -5657.4\n",
      "668     -5593.7\n",
      "669    -66305.7\n",
      "670   -126788.2\n",
      "671     21771.1\n",
      "672      7906.3\n",
      "673     -7108.8\n",
      "674     -2657.4\n",
      "675    -10530.6\n",
      "676     -1975.7\n",
      "677     -9657.4\n",
      "678    -13499.4\n",
      "679    -12499.4\n",
      "680    -11499.4\n",
      "681      5078.7\n",
      "682      1024.3\n",
      "683       906.3\n",
      "684     -3612.5\n",
      "685    -12237.3\n",
      "686     -6239.6\n",
      "687     11906.3\n",
      "688     -2188.4\n",
      "689     -2804.3\n",
      "690     -7657.4\n",
      "691     -1934.2\n",
      "692     -8975.7\n",
      "693     -1340.4\n",
      "694        24.3\n",
      "695     -3062.9\n",
      "696   -108826.6\n",
      "697     -4657.4\n",
      "698    -17992.2\n",
      "699     -4514.9\n",
      "700    -11771.7\n",
      "701    -12421.4\n",
      "702     -5301.0\n",
      "703     -6093.7\n",
      "704      1397.5\n",
      "705    -11065.2\n",
      "706     -4731.0\n",
      "707      8342.6\n",
      "708     -3982.6\n",
      "709     -3231.0\n",
      "710     -2421.3\n",
      "711      2659.6\n",
      "712     -9162.4\n",
      "713   -135307.6\n",
      "714     -2301.1\n",
      "715     -4657.4\n",
      "716    -51044.4\n",
      "717    -12204.0\n",
      "718     -4657.4\n",
      "719     -6431.7\n",
      "720        24.3\n",
      "721     -3731.0\n",
      "722     -1927.4\n",
      "723       642.4\n",
      "724      4867.1\n",
      "725     -3964.6\n",
      "726    -14610.3\n",
      "727    -46692.0\n",
      "728    -20748.0\n",
      "729     -9256.3\n",
      "730     -6921.3\n",
      "731     -3657.4\n",
      "732     -4314.9\n",
      "733     -6627.8\n",
      "734    -14204.0\n",
      "735     11485.7\n",
      "736    -16431.7\n",
      "737    -16431.7\n",
      "738     -8081.9\n",
      "739      2762.7\n",
      "740     -4982.6\n",
      "741     -4184.6\n",
      "742    -13805.5\n",
      "743    -31397.6\n",
      "744      7558.1\n",
      "745     -7237.3\n",
      "dtype: float64\n",
      "Posted On                  2022-05-06\n",
      "BHK                                 2\n",
      "Rent                           130000\n",
      "Size                              130\n",
      "Floor                      1 out of 1\n",
      "Area Type                  Super Area\n",
      "Area Locality             Lal Darwaza\n",
      "City                        Hyderabad\n",
      "Furnishing Status         Unfurnished\n",
      "Tenant Preferred     Bachelors/Family\n",
      "Bathroom                            2\n",
      "Point of Contact        Contact Owner\n",
      "Name: 4004, dtype: object\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "#preds=nearly.iloc[:,len(test.columns):]\n",
    "#print(preds.T.mean().tolist())\n",
    "#print(nearly[['Rent', 'final_predictions']])\n",
    "print(nearly['Rent']-nearly['final_predictions']) \n",
    "#print(nearly.loc[4:8,:])\n",
    "query=pd.read_csv('data\\House_Rent_Dataset.csv')\n",
    "print(query.loc[4004,:])\n",
    "#print(query[query['Floor']=='1 out of 1'])\n",
    "print(len(query['Floor'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e56d1",
   "metadata": {},
   "source": [
    "### How is algorithm performing?\n",
    "We have reached a point where we are making predictions, based on the average across 10 decision trees in a random forest model training on the complete data set. \n",
    "\n",
    "I still to think about how I sample the feature columns in the decision tree when I need to use OneHotEncoding on some of them. This issue means I have left out the Area Locality, which frankly I don't think is suited this type of algorithm as there are over 2000 different values and they are of course strings instead of continuous data. \n",
    "\n",
    "Equally, the floor type has 480 different values so doesnt lend itself to beign treated with the one-hot-encoder either. The greatest problem with this is that if I have already applied the encoder and then I run it through trees where we are only paying attention to $\\frac{1}{3}$ of the feature columns, these are completely dominated by the floor columns. \n",
    "\n",
    "Basically, I have concerns about how suitable the data set and its features are to be used in this type of regression model. \n",
    "\n",
    "A next and important step would be to test the algorithm with a new data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4103b27",
   "metadata": {},
   "source": [
    "### Mean Absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6c95991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6028712711497887\n"
     ]
    }
   ],
   "source": [
    "#print(nearly['final_predictions'])\n",
    "abso=(nearly['Rent']-nearly['final_predictions']).abs()\n",
    "perc=abso/nearly['Rent']\n",
    "print(perc.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
